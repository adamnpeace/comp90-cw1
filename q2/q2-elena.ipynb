{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "plt.set_cmap(\"gray\") # Otherwise grayscale images look purple\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TarFile.close of <tarfile.TarFile object at 0x000001CE0FA490B8>>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://udon.stacken.kth.se/~ninjin/comp0090_assignment_1_data.tar.gz'\n",
    "ftpstream = urllib.request.urlopen(url)\n",
    "tar = tarfile.open(fileobj=ftpstream, mode=\"r|gz\")\n",
    "tar.extractall()\n",
    "tar.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainxs = np.load(\"comp0090_assignment_1_data/fashion-train-imgs.npz\").transpose((2, 1, 0))\n",
    "trainys = np.load(\"comp0090_assignment_1_data/fashion-train-labels.npz\")\n",
    "devxs   = np.load(\"comp0090_assignment_1_data/fashion-dev-imgs.npz\").transpose((2, 1, 0))\n",
    "devys   = np.load(\"comp0090_assignment_1_data/fashion-dev-labels.npz\")\n",
    "testxs  = np.load(\"comp0090_assignment_1_data/fashion-test-imgs.npz\").transpose((2, 1, 0))\n",
    "testys  = np.load(\"comp0090_assignment_1_data/fashion-test-labels.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 28, 28)\n",
      "(12000,)\n",
      "(1000, 28, 28)\n",
      "(1000,)\n",
      "(1000, 28, 28)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(trainxs.shape)\n",
    "print(trainys.shape)\n",
    "print(devxs.shape)\n",
    "print(devys.shape)\n",
    "print(testxs.shape)\n",
    "print(testys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(4,4)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axarr[i, j].imshow(trainxs[np.random.randint(0, len(trainxs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data to make it easier to work with\n",
    "trainxs = trainxs.reshape(-1, 784)\n",
    "devxs = devxs.reshape(-1, 784)\n",
    "testxs = testxs.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create weight and sum parameters for the algorithm\n",
    "def initialise_parameters(xs):\n",
    "    w = np.zeros(xs.shape[1])\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic function definition\n",
    "def logistic_func(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# logistic function derivative definition\n",
    "def logistic_der(x):\n",
    "    return logistic_func(x) * (1 - logistic_func(x))\n",
    "\n",
    "# target function of logistic regression \n",
    "def f(x, w, b):\n",
    "    return logistic_func(np.dot(w, x) + b)\n",
    "\n",
    "# probability threshold\n",
    "def p(x, w, b):\n",
    "    if f(x, w, b) >= 0.5:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure accuracy\n",
    "def accuracy(xs, ys, w, b):\n",
    "    correct = 0\n",
    "    for i in range(xs.shape[0]):\n",
    "        if p(xs[i], w, b) == ys[i]:\n",
    "            correct += 1\n",
    "    return correct/len(xs)*100    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure MSE loss\n",
    "def loss_func(ys, y_predict):\n",
    "    sum = 0\n",
    "    n = ys.shape[0]\n",
    "    for i in range(n):\n",
    "        sum += (ys[i] - y_predict[i]) ** 2\n",
    "    return sum / (2*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure MSE loss for single data points\n",
    "def loss(y, y_hat):\n",
    "    return ((y - y_hat) ** 2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate prediction for y on validation set\n",
    "def validation_predictions(devxs, devys, w, b):\n",
    "    y_predict = []\n",
    "    \n",
    "    for i in range(devxs.shape[0]):\n",
    "        y_hat = f(devxs[i], w, b)\n",
    "        y_predict.append(y_hat)\n",
    "        \n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression model main function\n",
    "def logistic_regression(trainxs, trainys, devxs, devys):\n",
    "    w, b = initialise_parameters(trainxs)\n",
    "    y_predict = []\n",
    "    \n",
    "    # store accuracy and loss metrics for each epoch\n",
    "    accuracy_training = []\n",
    "    accuracy_validation = []\n",
    "    \n",
    "    loss_training = []\n",
    "    loss_validation = []\n",
    "    \n",
    "    mse_train_list = []\n",
    "    mse_val_list = []\n",
    "    \n",
    "    # store old accuracy and consecutive epochs count to detect convergence\n",
    "    loss_old = loss_func(devys, validation_predictions(devxs, devys, w, b))\n",
    "    row_epoch = 0\n",
    "    \n",
    "    # store number of epochs to have a nice graph\n",
    "    epoch = 0\n",
    "    learning_rate = 0.1\n",
    "    \n",
    "    while True:\n",
    "        print('Epoch', epoch)\n",
    "        trainxs, trainys = shuffle(trainxs, trainys)\n",
    "        grad_w, grad_b = initialise_parameters(trainxs)\n",
    "        y_predict = []\n",
    "\n",
    "        for i in range(trainxs.shape[0]):\n",
    "            y_hat = f(trainxs[i], w, b)\n",
    "            y_predict.append(y_hat)\n",
    "            grad_w += trainxs[i] * (y_hat - trainys[i]) * (1 - y_hat) * y_hat \n",
    "            grad_b += (y_hat - trainys[i]) * (1 - y_hat) * y_hat \n",
    "\n",
    "        grad_w /= trainxs.shape[0]\n",
    "        grad_b /= trainxs.shape[0]\n",
    "        w -= learning_rate * grad_w\n",
    "        b -= learning_rate * grad_b\n",
    "\n",
    "        accuracy_train = accuracy(trainxs, trainys, w, b)\n",
    "        accuracy_training.append(accuracy_train)\n",
    "        print('Training set accuracy:', accuracy(trainxs, trainys, w, b))\n",
    "        accuracy_dev = accuracy(devxs, devys, w, b)\n",
    "        accuracy_validation.append(accuracy_dev)\n",
    "        print('Validation set accuracy:', accuracy_dev)\n",
    "        \n",
    "        loss_train = loss_func(trainys, y_predict)\n",
    "        loss_training.append(loss_train)\n",
    "        print('Training set loss:', loss_train)\n",
    "        loss_dev = loss_func(devys, validation_predictions(devxs, devys, w, b))\n",
    "        loss_validation.append(loss_dev)\n",
    "        print('Validation set loss:', loss_dev)\n",
    "        \n",
    "        mse_training = mean_squared_error(trainys, y_predict)/2\n",
    "        mse_train_list.append(mse_training)\n",
    "        mse_validation = mean_squared_error(devys, validation_predictions(devxs, devys, w, b))/2\n",
    "        mse_val_list.append(mse_validation)\n",
    "        \n",
    "        # check if converged\n",
    "        if np.abs(loss_dev - loss_old) < 0.00001:\n",
    "            row_epoch += 1\n",
    "            if row_epoch == 5:\n",
    "                break\n",
    "        else:\n",
    "            row_epoch = 0\n",
    "            \n",
    "        loss_old = loss_dev\n",
    "        epoch += 1\n",
    "    \n",
    "    return epoch, accuracy_training, accuracy_validation, loss_training, loss_validation, mse_train_list, mse_val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training set accuracy: 55.95833333333333\n",
      "Validation set accuracy: 56.89999999999999\n",
      "Training set loss: 0.125\n",
      "Validation set loss: 0.11715526461237143\n",
      "Epoch 1\n",
      "Training set accuracy: 66.4\n",
      "Validation set accuracy: 68.4\n",
      "Training set loss: 0.11758031575658451\n",
      "Validation set loss: 0.11166747791745216\n",
      "Epoch 2\n",
      "Training set accuracy: 71.98333333333333\n",
      "Validation set accuracy: 71.89999999999999\n",
      "Training set loss: 0.11214173444297762\n",
      "Validation set loss: 0.10685128822965709\n",
      "Epoch 3\n",
      "Training set accuracy: 76.40833333333333\n",
      "Validation set accuracy: 76.2\n",
      "Training set loss: 0.10732754581143043\n",
      "Validation set loss: 0.10257258197945791\n",
      "Epoch 4\n",
      "Training set accuracy: 78.34166666666667\n",
      "Validation set accuracy: 78.8\n",
      "Training set loss: 0.10306007592268604\n",
      "Validation set loss: 0.09876912731742027\n",
      "Epoch 5\n",
      "Training set accuracy: 79.48333333333333\n",
      "Validation set accuracy: 80.2\n",
      "Training set loss: 0.09927988984547208\n",
      "Validation set loss: 0.09538216917298473\n",
      "Epoch 6\n",
      "Training set accuracy: 80.15\n",
      "Validation set accuracy: 80.7\n",
      "Training set loss: 0.09592490463979289\n",
      "Validation set loss: 0.0923557504513331\n",
      "Epoch 7\n",
      "Training set accuracy: 80.48333333333333\n",
      "Validation set accuracy: 81.10000000000001\n",
      "Training set loss: 0.09293625800817175\n",
      "Validation set loss: 0.08963916553053888\n",
      "Epoch 8\n",
      "Training set accuracy: 80.80833333333334\n",
      "Validation set accuracy: 81.6\n",
      "Training set loss: 0.09026113728526246\n",
      "Validation set loss: 0.08718804628863794\n",
      "Epoch 9\n",
      "Training set accuracy: 81.10833333333333\n",
      "Validation set accuracy: 81.89999999999999\n",
      "Training set loss: 0.0878536716342815\n",
      "Validation set loss: 0.08496438531543041\n",
      "Epoch 10\n",
      "Training set accuracy: 81.15833333333333\n",
      "Validation set accuracy: 82.19999999999999\n",
      "Training set loss: 0.08567478400541657\n",
      "Validation set loss: 0.08293602219731289\n",
      "Epoch 11\n",
      "Training set accuracy: 81.34166666666667\n",
      "Validation set accuracy: 82.0\n",
      "Training set loss: 0.0836915540787874\n",
      "Validation set loss: 0.08107592122327405\n",
      "Epoch 12\n",
      "Training set accuracy: 81.475\n",
      "Validation set accuracy: 82.1\n",
      "Training set loss: 0.08187640814059809\n",
      "Validation set loss: 0.07936141644750593\n",
      "Epoch 13\n",
      "Training set accuracy: 81.64166666666667\n",
      "Validation set accuracy: 82.19999999999999\n",
      "Training set loss: 0.08020630157100063\n",
      "Validation set loss: 0.07777350848691052\n",
      "Epoch 14\n",
      "Training set accuracy: 81.675\n",
      "Validation set accuracy: 82.3\n",
      "Training set loss: 0.07866197101512347\n",
      "Validation set loss: 0.07629624660415579\n",
      "Epoch 15\n",
      "Training set accuracy: 81.875\n",
      "Validation set accuracy: 82.5\n",
      "Training set loss: 0.07722728458738957\n",
      "Validation set loss: 0.07491620324667636\n",
      "Epoch 16\n",
      "Training set accuracy: 82.03333333333333\n",
      "Validation set accuracy: 82.89999999999999\n",
      "Training set loss: 0.07588869358033244\n",
      "Validation set loss: 0.07362203569088266\n",
      "Epoch 17\n",
      "Training set accuracy: 82.21666666666667\n",
      "Validation set accuracy: 83.0\n",
      "Training set loss: 0.07463477770364585\n",
      "Validation set loss: 0.07240412439839536\n",
      "Epoch 18\n",
      "Training set accuracy: 82.425\n",
      "Validation set accuracy: 83.3\n",
      "Training set loss: 0.07345587160436161\n",
      "Validation set loss: 0.07125427646638344\n",
      "Epoch 19\n",
      "Training set accuracy: 82.53333333333333\n",
      "Validation set accuracy: 83.7\n",
      "Training set loss: 0.07234375973883186\n",
      "Validation set loss: 0.07016548312837217\n",
      "Epoch 20\n",
      "Training set accuracy: 82.825\n",
      "Validation set accuracy: 84.5\n",
      "Training set loss: 0.0712914276258896\n",
      "Validation set loss: 0.06913172156509372\n",
      "Epoch 21\n",
      "Training set accuracy: 83.075\n",
      "Validation set accuracy: 84.8\n",
      "Training set loss: 0.07029285908435196\n",
      "Validation set loss: 0.0681477927768012\n",
      "Epoch 22\n",
      "Training set accuracy: 83.25833333333334\n",
      "Validation set accuracy: 85.0\n",
      "Training set loss: 0.06934287074019457\n",
      "Validation set loss: 0.06720918869563675\n",
      "Epoch 23\n",
      "Training set accuracy: 83.46666666666667\n",
      "Validation set accuracy: 85.2\n",
      "Training set loss: 0.06843697664989147\n",
      "Validation set loss: 0.06631198297624825\n",
      "Epoch 24\n",
      "Training set accuracy: 83.7\n",
      "Validation set accuracy: 85.7\n",
      "Training set loss: 0.06757127724051348\n",
      "Validation set loss: 0.06545274096736219\n",
      "Epoch 25\n",
      "Training set accuracy: 84.0\n",
      "Validation set accuracy: 86.0\n",
      "Training set loss: 0.06674236789856454\n",
      "Validation set loss: 0.06462844524415984\n",
      "Epoch 26\n",
      "Training set accuracy: 84.21666666666667\n",
      "Validation set accuracy: 86.2\n",
      "Training set loss: 0.06594726346415948\n",
      "Validation set loss: 0.06383643379308489\n",
      "Epoch 27\n",
      "Training set accuracy: 84.43333333333334\n",
      "Validation set accuracy: 86.5\n",
      "Training set loss: 0.06518333563280891\n",
      "Validation set loss: 0.06307434851302392\n",
      "Epoch 28\n",
      "Training set accuracy: 84.775\n",
      "Validation set accuracy: 86.8\n",
      "Training set loss: 0.06444826086361166\n",
      "Validation set loss: 0.062340092154586926\n",
      "Epoch 29\n",
      "Training set accuracy: 85.02499999999999\n",
      "Validation set accuracy: 87.4\n",
      "Training set loss: 0.06373997686792146\n",
      "Validation set loss: 0.06163179218444901\n",
      "Epoch 30\n",
      "Training set accuracy: 85.36666666666667\n",
      "Validation set accuracy: 87.7\n",
      "Training set loss: 0.06305664613036482\n",
      "Validation set loss: 0.060947770352885094\n",
      "Epoch 31\n",
      "Training set accuracy: 85.65833333333333\n",
      "Validation set accuracy: 88.2\n",
      "Training set loss: 0.0623966252144197\n",
      "Validation set loss: 0.06028651697490515\n",
      "Epoch 32\n",
      "Training set accuracy: 85.90833333333333\n",
      "Validation set accuracy: 88.3\n",
      "Training set loss: 0.06175843884370662\n",
      "Validation set loss: 0.05964666912094636\n",
      "Epoch 33\n",
      "Training set accuracy: 86.18333333333334\n",
      "Validation set accuracy: 88.7\n",
      "Training set loss: 0.061140757940567295\n",
      "Validation set loss: 0.05902699206163894\n",
      "Epoch 34\n",
      "Training set accuracy: 86.58333333333333\n",
      "Validation set accuracy: 88.8\n",
      "Training set loss: 0.06054238095565239\n",
      "Validation set loss: 0.058426363430412374\n",
      "Epoch 35\n",
      "Training set accuracy: 86.93333333333332\n",
      "Validation set accuracy: 88.9\n",
      "Training set loss: 0.059962217944136434\n",
      "Validation set loss: 0.0578437596637105\n",
      "Epoch 36\n",
      "Training set accuracy: 87.175\n",
      "Validation set accuracy: 88.9\n",
      "Training set loss: 0.05939927694213513\n",
      "Validation set loss: 0.05727824435613924\n",
      "Epoch 37\n",
      "Training set accuracy: 87.43333333333332\n",
      "Validation set accuracy: 89.2\n",
      "Training set loss: 0.05885265227592167\n",
      "Validation set loss: 0.05672895823070404\n",
      "Epoch 38\n",
      "Training set accuracy: 87.63333333333333\n",
      "Validation set accuracy: 89.4\n",
      "Training set loss: 0.05832151450044219\n",
      "Validation set loss: 0.056195110475407276\n",
      "Epoch 39\n",
      "Training set accuracy: 87.93333333333334\n",
      "Validation set accuracy: 89.7\n",
      "Training set loss: 0.05780510171557849\n",
      "Validation set loss: 0.0556759712391761\n",
      "Epoch 40\n",
      "Training set accuracy: 88.14999999999999\n",
      "Validation set accuracy: 89.8\n",
      "Training set loss: 0.05730271205090939\n",
      "Validation set loss: 0.05517086511424367\n",
      "Epoch 41\n",
      "Training set accuracy: 88.38333333333334\n",
      "Validation set accuracy: 90.2\n",
      "Training set loss: 0.05681369714433769\n",
      "Validation set loss: 0.05467916546017443\n",
      "Epoch 42\n",
      "Training set accuracy: 88.625\n",
      "Validation set accuracy: 90.3\n",
      "Training set loss: 0.05633745646839378\n",
      "Validation set loss: 0.05420028944786529\n",
      "Epoch 43\n",
      "Training set accuracy: 88.79166666666667\n",
      "Validation set accuracy: 90.4\n",
      "Training set loss: 0.05587343238140005\n",
      "Validation set loss: 0.05373369372099872\n",
      "Epoch 44\n",
      "Training set accuracy: 89.1\n",
      "Validation set accuracy: 90.60000000000001\n",
      "Training set loss: 0.055421105800083914\n",
      "Validation set loss: 0.053278870588319927\n",
      "Epoch 45\n",
      "Training set accuracy: 89.35833333333333\n",
      "Validation set accuracy: 90.8\n",
      "Training set loss: 0.05497999240624539\n",
      "Validation set loss: 0.0528353446733419\n",
      "Epoch 46\n",
      "Training set accuracy: 89.55\n",
      "Validation set accuracy: 90.8\n",
      "Training set loss: 0.054549639313468\n",
      "Validation set loss: 0.05240266995913239\n",
      "Epoch 47\n",
      "Training set accuracy: 89.725\n",
      "Validation set accuracy: 91.2\n",
      "Training set loss: 0.05412962213101153\n",
      "Validation set loss: 0.051980427175100416\n",
      "Epoch 48\n",
      "Training set accuracy: 89.91666666666667\n",
      "Validation set accuracy: 91.60000000000001\n",
      "Training set loss: 0.0537195423713658\n",
      "Validation set loss: 0.05156822148047535\n",
      "Epoch 49\n",
      "Training set accuracy: 90.14999999999999\n",
      "Validation set accuracy: 91.8\n",
      "Training set loss: 0.05331902515579018\n",
      "Validation set loss: 0.05116568040572193\n",
      "Epoch 50\n",
      "Training set accuracy: 90.31666666666666\n",
      "Validation set accuracy: 91.8\n",
      "Training set loss: 0.05292771717876715\n",
      "Validation set loss: 0.05077245201867048\n",
      "Epoch 51\n",
      "Training set accuracy: 90.49166666666667\n",
      "Validation set accuracy: 91.9\n",
      "Training set loss: 0.05254528489788737\n",
      "Validation set loss: 0.05038820328682427\n",
      "Epoch 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 90.675\n",
      "Validation set accuracy: 92.0\n",
      "Training set loss: 0.052171412920391284\n",
      "Validation set loss: 0.05001261861127951\n",
      "Epoch 53\n",
      "Training set accuracy: 90.85\n",
      "Validation set accuracy: 92.0\n",
      "Training set loss: 0.05180580256160924\n",
      "Validation set loss: 0.049645398511079866\n",
      "Epoch 54\n",
      "Training set accuracy: 91.00833333333334\n",
      "Validation set accuracy: 92.0\n",
      "Training set loss: 0.051448170553954634\n",
      "Validation set loss: 0.04928625843969878\n",
      "Epoch 55\n",
      "Training set accuracy: 91.14999999999999\n",
      "Validation set accuracy: 92.10000000000001\n",
      "Training set loss: 0.051098247888015806\n",
      "Validation set loss: 0.048934927717816434\n",
      "Epoch 56\n",
      "Training set accuracy: 91.28333333333333\n",
      "Validation set accuracy: 92.2\n",
      "Training set loss: 0.05075577876979375\n",
      "Validation set loss: 0.048591148568652404\n",
      "Epoch 57\n",
      "Training set accuracy: 91.38333333333334\n",
      "Validation set accuracy: 92.4\n",
      "Training set loss: 0.05042051968024133\n",
      "Validation set loss: 0.048254675243929006\n",
      "Epoch 58\n",
      "Training set accuracy: 91.50833333333334\n",
      "Validation set accuracy: 92.60000000000001\n",
      "Training set loss: 0.05009223852508464\n",
      "Validation set loss: 0.04792527323008433\n",
      "Epoch 59\n",
      "Training set accuracy: 91.55833333333334\n",
      "Validation set accuracy: 92.80000000000001\n",
      "Training set loss: 0.049770713864482084\n",
      "Validation set loss: 0.04760271852569389\n",
      "Epoch 60\n",
      "Training set accuracy: 91.675\n",
      "Validation set accuracy: 92.9\n",
      "Training set loss: 0.04945573421340563\n",
      "Validation set loss: 0.04728679698220234\n",
      "Epoch 61\n",
      "Training set accuracy: 91.75833333333333\n",
      "Validation set accuracy: 93.0\n",
      "Training set loss: 0.04914709740480921\n",
      "Validation set loss: 0.04697730370106485\n",
      "Epoch 62\n",
      "Training set accuracy: 91.85\n",
      "Validation set accuracy: 93.10000000000001\n",
      "Training set loss: 0.04884461000863083\n",
      "Validation set loss: 0.046674042481251746\n",
      "Epoch 63\n",
      "Training set accuracy: 91.95833333333333\n",
      "Validation set accuracy: 93.2\n",
      "Training set loss: 0.04854808680055486\n",
      "Validation set loss: 0.04637682531181064\n",
      "Epoch 64\n",
      "Training set accuracy: 92.11666666666667\n",
      "Validation set accuracy: 93.30000000000001\n",
      "Training set loss: 0.04825735027521085\n",
      "Validation set loss: 0.04608547190482959\n",
      "Epoch 65\n",
      "Training set accuracy: 92.25\n",
      "Validation set accuracy: 93.5\n",
      "Training set loss: 0.04797223019912287\n",
      "Validation set loss: 0.045799809264694735\n",
      "Epoch 66\n",
      "Training set accuracy: 92.375\n",
      "Validation set accuracy: 93.7\n",
      "Training set loss: 0.04769256319930014\n",
      "Validation set loss: 0.04551967129002873\n",
      "Epoch 67\n",
      "Training set accuracy: 92.40833333333333\n",
      "Validation set accuracy: 93.8\n",
      "Training set loss: 0.04741819238384687\n",
      "Validation set loss: 0.04524489840511704\n",
      "Epoch 68\n",
      "Training set accuracy: 92.50833333333334\n",
      "Validation set accuracy: 93.8\n",
      "Training set loss: 0.04714896699139489\n",
      "Validation set loss: 0.044975337217992094\n",
      "Epoch 69\n",
      "Training set accuracy: 92.59166666666667\n",
      "Validation set accuracy: 93.8\n",
      "Training set loss: 0.04688474206653154\n",
      "Validation set loss: 0.0447108402026763\n",
      "Epoch 70\n",
      "Training set accuracy: 92.65\n",
      "Validation set accuracy: 93.89999999999999\n",
      "Training set loss: 0.04662537815873078\n",
      "Validation set loss: 0.04445126540335755\n",
      "Epoch 71\n",
      "Training set accuracy: 92.70833333333334\n",
      "Validation set accuracy: 93.89999999999999\n",
      "Training set loss: 0.046370741042565944\n",
      "Validation set loss: 0.04419647615852155\n",
      "Epoch 72\n",
      "Training set accuracy: 92.77499999999999\n",
      "Validation set accuracy: 94.1\n",
      "Training set loss: 0.04612070145724333\n",
      "Validation set loss: 0.04394634084327889\n",
      "Epoch 73\n",
      "Training set accuracy: 92.84166666666667\n",
      "Validation set accuracy: 94.1\n",
      "Training set loss: 0.04587513486370145\n",
      "Validation set loss: 0.04370073262831513\n",
      "Epoch 74\n",
      "Training set accuracy: 92.89166666666667\n",
      "Validation set accuracy: 94.19999999999999\n",
      "Training set loss: 0.045633921217722466\n",
      "Validation set loss: 0.04345952925405715\n",
      "Epoch 75\n",
      "Training set accuracy: 92.95\n",
      "Validation set accuracy: 94.19999999999999\n",
      "Training set loss: 0.04539694475766581\n",
      "Validation set loss: 0.0432226128187967\n",
      "Epoch 76\n",
      "Training set accuracy: 93.025\n",
      "Validation set accuracy: 94.19999999999999\n",
      "Training set loss: 0.045164093805572736\n",
      "Validation set loss: 0.04298986957964047\n",
      "Epoch 77\n",
      "Training set accuracy: 93.075\n",
      "Validation set accuracy: 94.19999999999999\n",
      "Training set loss: 0.044935260580538997\n",
      "Validation set loss: 0.04276118976526884\n",
      "Epoch 78\n",
      "Training set accuracy: 93.09166666666667\n",
      "Validation set accuracy: 94.19999999999999\n",
      "Training set loss: 0.04471034102335061\n",
      "Validation set loss: 0.04253646739958819\n",
      "Epoch 79\n",
      "Training set accuracy: 93.15\n",
      "Validation set accuracy: 94.39999999999999\n",
      "Training set loss: 0.044489234631480856\n",
      "Validation set loss: 0.04231560013544957\n",
      "Epoch 80\n",
      "Training set accuracy: 93.2\n",
      "Validation set accuracy: 94.39999999999999\n",
      "Training set loss: 0.044271844303652066\n",
      "Validation set loss: 0.04209848909768437\n",
      "Epoch 81\n",
      "Training set accuracy: 93.25833333333333\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 0.04405807619321833\n",
      "Validation set loss: 0.04188503873478072\n",
      "Epoch 82\n",
      "Training set accuracy: 93.34166666666667\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 0.043847839569719285\n",
      "Validation set loss: 0.041675156678584305\n",
      "Epoch 83\n",
      "Training set accuracy: 93.375\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 0.04364104668800408\n",
      "Validation set loss: 0.04146875361146278\n",
      "Epoch 84\n",
      "Training set accuracy: 93.425\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 0.04343761266438407\n",
      "Validation set loss: 0.04126574314042514\n",
      "Epoch 85\n",
      "Training set accuracy: 93.46666666666667\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 0.04323745535932283\n",
      "Validation set loss: 0.041066041677729016\n",
      "Epoch 86\n",
      "Training set accuracy: 93.54166666666667\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 0.043040495266212245\n",
      "Validation set loss: 0.040869568327549476\n",
      "Epoch 87\n",
      "Training set accuracy: 93.58333333333333\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 0.0428466554058298\n",
      "Validation set loss: 0.040676244778320034\n",
      "Epoch 88\n",
      "Training set accuracy: 93.65\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 0.042655861226098116\n",
      "Validation set loss: 0.04048599520038461\n",
      "Epoch 89\n",
      "Training set accuracy: 93.69166666666666\n",
      "Validation set accuracy: 94.6\n",
      "Training set loss: 0.042468040506809177\n",
      "Validation set loss: 0.04029874614863513\n",
      "Epoch 90\n",
      "Training set accuracy: 93.75\n",
      "Validation set accuracy: 94.6\n",
      "Training set loss: 0.04228312326899567\n",
      "Validation set loss: 0.04011442646982465\n",
      "Epoch 91\n",
      "Training set accuracy: 93.77499999999999\n",
      "Validation set accuracy: 94.69999999999999\n",
      "Training set loss: 0.042101041688662265\n",
      "Validation set loss: 0.03993296721428275\n",
      "Epoch 92\n",
      "Training set accuracy: 93.8\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 0.04192173001460976\n",
      "Validation set loss: 0.03975430155176804\n",
      "Epoch 93\n",
      "Training set accuracy: 93.80833333333334\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 0.04174512449011047\n",
      "Validation set loss: 0.039578364691221564\n",
      "Epoch 94\n",
      "Training set accuracy: 93.83333333333333\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 0.04157116327820437\n",
      "Validation set loss: 0.03940509380419776\n",
      "Epoch 95\n",
      "Training set accuracy: 93.86666666666666\n",
      "Validation set accuracy: 94.69999999999999\n",
      "Training set loss: 0.04139978639041006\n",
      "Validation set loss: 0.0392344279517654\n",
      "Epoch 96\n",
      "Training set accuracy: 93.875\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 0.041230935618653534\n",
      "Validation set loss: 0.03906630801468912\n",
      "Epoch 97\n",
      "Training set accuracy: 93.89166666666667\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 0.04106455447023764\n",
      "Validation set loss: 0.038900676626709346\n",
      "Epoch 98\n",
      "Training set accuracy: 93.91666666666667\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 0.04090058810568522\n",
      "Validation set loss: 0.0387374781107574\n",
      "Epoch 99\n",
      "Training set accuracy: 93.95833333333333\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 0.04073898327929607\n",
      "Validation set loss: 0.0385766584179479\n",
      "Epoch 100\n",
      "Training set accuracy: 93.95833333333333\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 0.04057968828227662\n",
      "Validation set loss: 0.038418165069203786\n",
      "Epoch 101\n",
      "Training set accuracy: 93.99166666666666\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 0.04042265288830825\n",
      "Validation set loss: 0.03826194709937816\n",
      "Epoch 102\n",
      "Training set accuracy: 94.04166666666667\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 0.040267828301422\n",
      "Validation set loss: 0.03810795500374512\n",
      "Epoch 103\n",
      "Training set accuracy: 94.05\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 0.04011516710606671\n",
      "Validation set loss: 0.037956140686740365\n",
      "Epoch 104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 94.075\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 0.03996462321925828\n",
      "Validation set loss: 0.037806457412838695\n",
      "Epoch 105\n",
      "Training set accuracy: 94.08333333333333\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 0.03981615184470496\n",
      "Validation set loss: 0.03765885975946416\n",
      "Epoch 106\n",
      "Training set accuracy: 94.075\n",
      "Validation set accuracy: 94.89999999999999\n",
      "Training set loss: 0.039669709428811255\n",
      "Validation set loss: 0.037513303571831864\n",
      "Epoch 107\n",
      "Training set accuracy: 94.09166666666667\n",
      "Validation set accuracy: 95.0\n",
      "Training set loss: 0.039525253618471756\n",
      "Validation set loss: 0.03736974591963002\n",
      "Epoch 108\n",
      "Training set accuracy: 94.1\n",
      "Validation set accuracy: 95.0\n",
      "Training set loss: 0.03938274322056393\n",
      "Validation set loss: 0.037228145055452765\n",
      "Epoch 109\n",
      "Training set accuracy: 94.10833333333333\n",
      "Validation set accuracy: 95.0\n",
      "Training set loss: 0.03924213816306279\n",
      "Validation set loss: 0.03708846037490156\n",
      "Epoch 110\n",
      "Training set accuracy: 94.125\n",
      "Validation set accuracy: 95.0\n",
      "Training set loss: 0.03910339945769963\n",
      "Validation set loss: 0.0369506523782765\n",
      "Epoch 111\n",
      "Training set accuracy: 94.15833333333333\n",
      "Validation set accuracy: 95.0\n",
      "Training set loss: 0.038966489164089256\n",
      "Validation set loss: 0.03681468263378332\n",
      "Epoch 112\n",
      "Training set accuracy: 94.20833333333334\n",
      "Validation set accuracy: 95.19999999999999\n",
      "Training set loss: 0.038831370355265384\n",
      "Validation set loss: 0.03668051374218687\n",
      "Epoch 113\n",
      "Training set accuracy: 94.22500000000001\n",
      "Validation set accuracy: 95.19999999999999\n",
      "Training set loss: 0.038698007084551296\n",
      "Validation set loss: 0.036548109302844446\n",
      "Epoch 114\n",
      "Training set accuracy: 94.23333333333333\n",
      "Validation set accuracy: 95.19999999999999\n",
      "Training set loss: 0.03856636435371101\n",
      "Validation set loss: 0.03641743388105663\n",
      "Epoch 115\n",
      "Training set accuracy: 94.25833333333333\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 0.03843640808231954\n",
      "Validation set loss: 0.03628845297667525\n",
      "Epoch 116\n",
      "Training set accuracy: 94.26666666666667\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 0.038308105078300264\n",
      "Validation set loss: 0.03616113299391512\n",
      "Epoch 117\n",
      "Training set accuracy: 94.28333333333333\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 0.03818142300957772\n",
      "Validation set loss: 0.03603544121231224\n",
      "Epoch 118\n",
      "Training set accuracy: 94.29166666666666\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 0.03805633037679261\n",
      "Validation set loss: 0.035911345758781785\n",
      "Epoch 119\n",
      "Training set accuracy: 94.30833333333334\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 0.03793279648704105\n",
      "Validation set loss: 0.03578881558072558\n",
      "Epoch 120\n",
      "Training set accuracy: 94.35\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 0.037810791428583346\n",
      "Validation set loss: 0.03566782042014414\n",
      "Epoch 121\n",
      "Training set accuracy: 94.35\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 0.03769028604649016\n",
      "Validation set loss: 0.03554833078871026\n",
      "Epoch 122\n",
      "Training set accuracy: 94.34166666666667\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 0.03757125191917993\n",
      "Validation set loss: 0.03543031794376265\n",
      "Epoch 123\n",
      "Training set accuracy: 94.35833333333333\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 0.03745366133581209\n",
      "Validation set loss: 0.035313753865181235\n",
      "Epoch 124\n",
      "Training set accuracy: 94.39166666666667\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 0.037337487274500515\n",
      "Validation set loss: 0.03519861123310531\n",
      "Epoch 125\n",
      "Training set accuracy: 94.39999999999999\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 0.03722270338131119\n",
      "Validation set loss: 0.03508486340646157\n",
      "Epoch 126\n",
      "Training set accuracy: 94.39166666666667\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 0.03710928395001406\n",
      "Validation set loss: 0.034972484402265726\n",
      "Epoch 127\n",
      "Training set accuracy: 94.39999999999999\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 0.036997203902556154\n",
      "Validation set loss: 0.03486144887566769\n",
      "Epoch 128\n",
      "Training set accuracy: 94.40833333333333\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.036886438770224544\n",
      "Validation set loss: 0.03475173210070795\n",
      "Epoch 129\n",
      "Training set accuracy: 94.41666666666667\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03677696467547742\n",
      "Validation set loss: 0.03464330995175829\n",
      "Epoch 130\n",
      "Training set accuracy: 94.44166666666666\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.036668758314409626\n",
      "Validation set loss: 0.03453615888561548\n",
      "Epoch 131\n",
      "Training set accuracy: 94.46666666666667\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03656179693982883\n",
      "Validation set loss: 0.03443025592422602\n",
      "Epoch 132\n",
      "Training set accuracy: 94.48333333333333\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.036456058344921674\n",
      "Validation set loss: 0.0343255786380123\n",
      "Epoch 133\n",
      "Training set accuracy: 94.49166666666666\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03635152084748081\n",
      "Validation set loss: 0.034222105129778586\n",
      "Epoch 134\n",
      "Training set accuracy: 94.50833333333334\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03624816327467471\n",
      "Validation set loss: 0.03411981401917354\n",
      "Epoch 135\n",
      "Training set accuracy: 94.53333333333333\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03614596494833684\n",
      "Validation set loss: 0.0340186844276855\n",
      "Epoch 136\n",
      "Training set accuracy: 94.54166666666667\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.036044905670755585\n",
      "Validation set loss: 0.03391869596415235\n",
      "Epoch 137\n",
      "Training set accuracy: 94.55833333333334\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.0359449657109427\n",
      "Validation set loss: 0.03381982871076305\n",
      "Epoch 138\n",
      "Training set accuracy: 94.575\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03584612579136548\n",
      "Validation set loss: 0.03372206320953371\n",
      "Epoch 139\n",
      "Training set accuracy: 94.59166666666667\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03574836707512068\n",
      "Validation set loss: 0.03362538044923851\n",
      "Epoch 140\n",
      "Training set accuracy: 94.6\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03565167115353826\n",
      "Validation set loss: 0.03352976185277841\n",
      "Epoch 141\n",
      "Training set accuracy: 94.59166666666667\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03555602003419149\n",
      "Validation set loss: 0.033435189264971264\n",
      "Epoch 142\n",
      "Training set accuracy: 94.61666666666667\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.0354613961293076\n",
      "Validation set loss: 0.03334164494074639\n",
      "Epoch 143\n",
      "Training set accuracy: 94.63333333333334\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.035367782244552386\n",
      "Validation set loss: 0.033249111533728865\n",
      "Epoch 144\n",
      "Training set accuracy: 94.625\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.035275161568186886\n",
      "Validation set loss: 0.03315757208519854\n",
      "Epoch 145\n",
      "Training set accuracy: 94.64166666666667\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.0351835176605719\n",
      "Validation set loss: 0.03306701001340979\n",
      "Epoch 146\n",
      "Training set accuracy: 94.65\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03509283444401305\n",
      "Validation set loss: 0.032977409103258394\n",
      "Epoch 147\n",
      "Training set accuracy: 94.66666666666667\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.035003096192932584\n",
      "Validation set loss: 0.03288875349628282\n",
      "Epoch 148\n",
      "Training set accuracy: 94.675\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.034914287524356095\n",
      "Validation set loss: 0.03280102768098704\n",
      "Epoch 149\n",
      "Training set accuracy: 94.675\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03482639338870209\n",
      "Validation set loss: 0.032714216483474\n",
      "Epoch 150\n",
      "Training set accuracy: 94.69166666666666\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.034739399060861854\n",
      "Validation set loss: 0.03262830505837675\n",
      "Epoch 151\n",
      "Training set accuracy: 94.69999999999999\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03465329013156406\n",
      "Validation set loss: 0.03254327888007805\n",
      "Epoch 152\n",
      "Training set accuracy: 94.70833333333334\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.0345680524990074\n",
      "Validation set loss: 0.032459123734206924\n",
      "Epoch 153\n",
      "Training set accuracy: 94.71666666666667\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03448367236075661\n",
      "Validation set loss: 0.03237582570940244\n",
      "Epoch 154\n",
      "Training set accuracy: 94.73333333333333\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03440013620588987\n",
      "Validation set loss: 0.03229337118933477\n",
      "Epoch 155\n",
      "Training set accuracy: 94.74166666666667\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03431743080738948\n",
      "Validation set loss: 0.03221174684497523\n",
      "Epoch 156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 94.75\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03423554321476818\n",
      "Validation set loss: 0.0321309396271051\n",
      "Epoch 157\n",
      "Training set accuracy: 94.75\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03415446074691877\n",
      "Validation set loss: 0.03205093675905566\n",
      "Epoch 158\n",
      "Training set accuracy: 94.76666666666667\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03407417098518436\n",
      "Validation set loss: 0.03197172572967112\n",
      "Epoch 159\n",
      "Training set accuracy: 94.76666666666667\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03399466176664029\n",
      "Validation set loss: 0.03189329428648644\n",
      "Epoch 160\n",
      "Training set accuracy: 94.79166666666666\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03391592117757664\n",
      "Validation set loss: 0.03181563042911234\n",
      "Epoch 161\n",
      "Training set accuracy: 94.8\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.033837937547178065\n",
      "Validation set loss: 0.031738722402820586\n",
      "Epoch 162\n",
      "Training set accuracy: 94.8\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03376069944139359\n",
      "Validation set loss: 0.031662558692322616\n",
      "Epoch 163\n",
      "Training set accuracy: 94.8\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03368419565698906\n",
      "Validation set loss: 0.03158712801573464\n",
      "Epoch 164\n",
      "Training set accuracy: 94.80833333333332\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.033608415215776836\n",
      "Validation set loss: 0.031512419318722514\n",
      "Epoch 165\n",
      "Training set accuracy: 94.81666666666668\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 0.03353334735901423\n",
      "Validation set loss: 0.03143842176882119\n",
      "Epoch 166\n",
      "Training set accuracy: 94.825\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.033458981541969954\n",
      "Validation set loss: 0.031365124749921404\n",
      "Epoch 167\n",
      "Training set accuracy: 94.83333333333334\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.03338530742864709\n",
      "Validation set loss: 0.031292517856919125\n",
      "Epoch 168\n",
      "Training set accuracy: 94.83333333333334\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.033312314886661185\n",
      "Validation set loss: 0.031220590890521812\n",
      "Epoch 169\n",
      "Training set accuracy: 94.84166666666667\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.03323999398226759\n",
      "Validation set loss: 0.03114933385220589\n",
      "Epoch 170\n",
      "Training set accuracy: 94.83333333333334\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.033168334975531656\n",
      "Validation set loss: 0.031078736939320936\n",
      "Epoch 171\n",
      "Training set accuracy: 94.84166666666667\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.03309732831563909\n",
      "Validation set loss: 0.03100879054033518\n",
      "Epoch 172\n",
      "Training set accuracy: 94.86666666666666\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.033026964636339536\n",
      "Validation set loss: 0.0309394852302179\n",
      "Epoch 173\n",
      "Training set accuracy: 94.85833333333333\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.03295723475152075\n",
      "Validation set loss: 0.030870811765954354\n",
      "Epoch 174\n",
      "Training set accuracy: 94.86666666666666\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.03288812965090965\n",
      "Validation set loss: 0.030802761082188275\n",
      "Epoch 175\n",
      "Training set accuracy: 94.86666666666666\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.03281964049589326\n",
      "Validation set loss: 0.030735324286988427\n",
      "Epoch 176\n",
      "Training set accuracy: 94.875\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.03275175861545861\n",
      "Validation set loss: 0.030668492657734477\n",
      "Epoch 177\n",
      "Training set accuracy: 94.88333333333333\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.03268447550224474\n",
      "Validation set loss: 0.03060225763711936\n",
      "Epoch 178\n",
      "Training set accuracy: 94.88333333333333\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.03261778280870832\n",
      "Validation set loss: 0.03053661082926292\n",
      "Epoch 179\n",
      "Training set accuracy: 94.89166666666667\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.032551672343392846\n",
      "Validation set loss: 0.03047154399593416\n",
      "Epoch 180\n",
      "Training set accuracy: 94.89166666666667\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.03248613606730178\n",
      "Validation set loss: 0.030407049052879193\n",
      "Epoch 181\n",
      "Training set accuracy: 94.90833333333333\n",
      "Validation set accuracy: 95.6\n",
      "Training set loss: 0.032421166090372724\n",
      "Validation set loss: 0.030343118066249695\n",
      "Epoch 182\n",
      "Training set accuracy: 94.91666666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.032356754668047535\n",
      "Validation set loss: 0.030279743249130305\n",
      "Epoch 183\n",
      "Training set accuracy: 94.91666666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03229289419793754\n",
      "Validation set loss: 0.030216916958161425\n",
      "Epoch 184\n",
      "Training set accuracy: 94.91666666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.032229577216575704\n",
      "Validation set loss: 0.03015463169025351\n",
      "Epoch 185\n",
      "Training set accuracy: 94.91666666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.032166796396262555\n",
      "Validation set loss: 0.030092880079391753\n",
      "Epoch 186\n",
      "Training set accuracy: 94.925\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03210454454199281\n",
      "Validation set loss: 0.030031654893526293\n",
      "Epoch 187\n",
      "Training set accuracy: 94.925\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03204281458846629\n",
      "Validation set loss: 0.029970949031546634\n",
      "Epoch 188\n",
      "Training set accuracy: 94.93333333333334\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03198159959717795\n",
      "Validation set loss: 0.029910755520337732\n",
      "Epoch 189\n",
      "Training set accuracy: 94.94166666666666\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03192089275358763\n",
      "Validation set loss: 0.02985106751191377\n",
      "Epoch 190\n",
      "Training set accuracy: 94.95\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03186068736436248\n",
      "Validation set loss: 0.029791878280629378\n",
      "Epoch 191\n",
      "Training set accuracy: 94.95833333333333\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.031800976854693394\n",
      "Validation set loss: 0.029733181220463676\n",
      "Epoch 192\n",
      "Training set accuracy: 94.95833333333333\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.031741754765681446\n",
      "Validation set loss: 0.02967496984237691\n",
      "Epoch 193\n",
      "Training set accuracy: 94.975\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03168301475179445\n",
      "Validation set loss: 0.029617237771736103\n",
      "Epoch 194\n",
      "Training set accuracy: 94.98333333333333\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.0316247505783889\n",
      "Validation set loss: 0.029559978745808162\n",
      "Epoch 195\n",
      "Training set accuracy: 94.98333333333333\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.031566956119294\n",
      "Validation set loss: 0.02950318661131828\n",
      "Epoch 196\n",
      "Training set accuracy: 95.0\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.031509625354463805\n",
      "Validation set loss: 0.029446855322071933\n",
      "Epoch 197\n",
      "Training set accuracy: 94.99166666666666\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03145275236768395\n",
      "Validation set loss: 0.02939097893663807\n",
      "Epoch 198\n",
      "Training set accuracy: 94.98333333333333\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03139633134434194\n",
      "Validation set loss: 0.029335551616092387\n",
      "Epoch 199\n",
      "Training set accuracy: 94.98333333333333\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.031340356569251215\n",
      "Validation set loss: 0.029280567621817896\n",
      "Epoch 200\n",
      "Training set accuracy: 94.99166666666666\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.0312848224245321\n",
      "Validation set loss: 0.02922602131336204\n",
      "Epoch 201\n",
      "Training set accuracy: 95.00833333333333\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.031229723387547557\n",
      "Validation set loss: 0.029171907146348375\n",
      "Epoch 202\n",
      "Training set accuracy: 95.00833333333333\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.031175054028888566\n",
      "Validation set loss: 0.02911821967044065\n",
      "Epoch 203\n",
      "Training set accuracy: 95.00833333333333\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03112080901041186\n",
      "Validation set loss: 0.029064953527359248\n",
      "Epoch 204\n",
      "Training set accuracy: 95.01666666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03106698308332736\n",
      "Validation set loss: 0.02901210344894607\n",
      "Epoch 205\n",
      "Training set accuracy: 95.025\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.031013571086332372\n",
      "Validation set loss: 0.028959664255279106\n",
      "Epoch 206\n",
      "Training set accuracy: 95.03333333333333\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.030960567943791168\n",
      "Validation set loss: 0.028907630852833224\n",
      "Epoch 207\n",
      "Training set accuracy: 95.04166666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03090796866396308\n",
      "Validation set loss: 0.028855998232687297\n",
      "Epoch 208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 95.05\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.030855768337270936\n",
      "Validation set loss: 0.028804761468774694\n",
      "Epoch 209\n",
      "Training set accuracy: 95.05\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03080396213461295\n",
      "Validation set loss: 0.028753915716177966\n",
      "Epoch 210\n",
      "Training set accuracy: 95.05833333333334\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.030752545305716965\n",
      "Validation set loss: 0.028703456209464382\n",
      "Epoch 211\n",
      "Training set accuracy: 95.05\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.030701513177534036\n",
      "Validation set loss: 0.028653378261063085\n",
      "Epoch 212\n",
      "Training set accuracy: 95.05833333333334\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03065086115267177\n",
      "Validation set loss: 0.028603677259680882\n",
      "Epoch 213\n",
      "Training set accuracy: 95.06666666666666\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03060058470786339\n",
      "Validation set loss: 0.02855434866875696\n",
      "Epoch 214\n",
      "Training set accuracy: 95.075\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.030550679392477298\n",
      "Validation set loss: 0.028505388024954642\n",
      "Epoch 215\n",
      "Training set accuracy: 95.09166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.030501140827059146\n",
      "Validation set loss: 0.02845679093668999\n",
      "Epoch 216\n",
      "Training set accuracy: 95.09166666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.030451964701909775\n",
      "Validation set loss: 0.02840855308269475\n",
      "Epoch 217\n",
      "Training set accuracy: 95.09166666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.030403146775698577\n",
      "Validation set loss: 0.028360670210614426\n",
      "Epoch 218\n",
      "Training set accuracy: 95.09166666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.030354682874108235\n",
      "Validation set loss: 0.028313138135639317\n",
      "Epoch 219\n",
      "Training set accuracy: 95.09166666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.030306568888510625\n",
      "Validation set loss: 0.028265952739167956\n",
      "Epoch 220\n",
      "Training set accuracy: 95.10833333333333\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.03025880077467709\n",
      "Validation set loss: 0.02821910996750228\n",
      "Epoch 221\n",
      "Training set accuracy: 95.10833333333333\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.030211374551515097\n",
      "Validation set loss: 0.028172605830573193\n",
      "Epoch 222\n",
      "Training set accuracy: 95.11666666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.030164286299837664\n",
      "Validation set loss: 0.02812643640069649\n",
      "Epoch 223\n",
      "Training set accuracy: 95.13333333333334\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.030117532161158964\n",
      "Validation set loss: 0.02808059781135713\n",
      "Epoch 224\n",
      "Training set accuracy: 95.13333333333334\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.030071108336520633\n",
      "Validation set loss: 0.028035086256022326\n",
      "Epoch 225\n",
      "Training set accuracy: 95.13333333333334\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.030025011085342106\n",
      "Validation set loss: 0.02798989798698182\n",
      "Epoch 226\n",
      "Training set accuracy: 95.14166666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.02997923672429975\n",
      "Validation set loss: 0.02794502931421499\n",
      "Epoch 227\n",
      "Training set accuracy: 95.15\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.029933781626230792\n",
      "Validation set loss: 0.027900476604283946\n",
      "Epoch 228\n",
      "Training set accuracy: 95.14166666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.029888642219061897\n",
      "Validation set loss: 0.027856236279252232\n",
      "Epoch 229\n",
      "Training set accuracy: 95.14166666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.02984381498476354\n",
      "Validation set loss: 0.02781230481562771\n",
      "Epoch 230\n",
      "Training set accuracy: 95.14166666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.029799296458326997\n",
      "Validation set loss: 0.027768678743330045\n",
      "Epoch 231\n",
      "Training set accuracy: 95.15833333333333\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.02975508322676401\n",
      "Validation set loss: 0.027725354644680913\n",
      "Epoch 232\n",
      "Training set accuracy: 95.15833333333333\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.02971117192813099\n",
      "Validation set loss: 0.027682329153417725\n",
      "Epoch 233\n",
      "Training set accuracy: 95.16666666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.029667559250572108\n",
      "Validation set loss: 0.02763959895372893\n",
      "Epoch 234\n",
      "Training set accuracy: 95.16666666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.029624241931387407\n",
      "Validation set loss: 0.027597160779311056\n",
      "Epoch 235\n",
      "Training set accuracy: 95.16666666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.02958121675611845\n",
      "Validation set loss: 0.027555011412447185\n",
      "Epoch 236\n",
      "Training set accuracy: 95.18333333333334\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.029538480557656063\n",
      "Validation set loss: 0.027513147683105362\n",
      "Epoch 237\n",
      "Training set accuracy: 95.19999999999999\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.029496030215367126\n",
      "Validation set loss: 0.0274715664680572\n",
      "Epoch 238\n",
      "Training set accuracy: 95.19999999999999\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.029453862654241235\n",
      "Validation set loss: 0.027430264690016182\n",
      "Epoch 239\n",
      "Training set accuracy: 95.19999999999999\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.02941197484405601\n",
      "Validation set loss: 0.027389239316794548\n",
      "Epoch 240\n",
      "Training set accuracy: 95.21666666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.029370363798558216\n",
      "Validation set loss: 0.02734848736047868\n",
      "Epoch 241\n",
      "Training set accuracy: 95.21666666666667\n",
      "Validation set accuracy: 95.7\n",
      "Training set loss: 0.029329026574668356\n",
      "Validation set loss: 0.027308005876623027\n",
      "Epoch 242\n",
      "Training set accuracy: 95.22500000000001\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02928796027169587\n",
      "Validation set loss: 0.027267791963460655\n",
      "Epoch 243\n",
      "Training set accuracy: 95.22500000000001\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.029247162030576496\n",
      "Validation set loss: 0.02722784276113188\n",
      "Epoch 244\n",
      "Training set accuracy: 95.22500000000001\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.029206629033123946\n",
      "Validation set loss: 0.027188155450928665\n",
      "Epoch 245\n",
      "Training set accuracy: 95.23333333333333\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.029166358501296064\n",
      "Validation set loss: 0.02714872725455619\n",
      "Epoch 246\n",
      "Training set accuracy: 95.23333333333333\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02912634769648163\n",
      "Validation set loss: 0.027109555433409486\n",
      "Epoch 247\n",
      "Training set accuracy: 95.23333333333333\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.029086593918796092\n",
      "Validation set loss: 0.027070637287865948\n",
      "Epoch 248\n",
      "Training set accuracy: 95.23333333333333\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.029047094506397315\n",
      "Validation set loss: 0.027031970156592713\n",
      "Epoch 249\n",
      "Training set accuracy: 95.22500000000001\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.029007846834813583\n",
      "Validation set loss: 0.026993551415869\n",
      "Epoch 250\n",
      "Training set accuracy: 95.21666666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028968848316286197\n",
      "Validation set loss: 0.026955378478922678\n",
      "Epoch 251\n",
      "Training set accuracy: 95.21666666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028930096399125645\n",
      "Validation set loss: 0.026917448795280588\n",
      "Epoch 252\n",
      "Training set accuracy: 95.22500000000001\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028891588567081097\n",
      "Validation set loss: 0.02687975985013268\n",
      "Epoch 253\n",
      "Training set accuracy: 95.22500000000001\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.0288533223387252\n",
      "Validation set loss: 0.026842309163709787\n",
      "Epoch 254\n",
      "Training set accuracy: 95.23333333333333\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028815295266847903\n",
      "Validation set loss: 0.02680509429067366\n",
      "Epoch 255\n",
      "Training set accuracy: 95.23333333333333\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02877750493786657\n",
      "Validation set loss: 0.026768112819520566\n",
      "Epoch 256\n",
      "Training set accuracy: 95.25\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028739948971245436\n",
      "Validation set loss: 0.02673136237199635\n",
      "Epoch 257\n",
      "Training set accuracy: 95.24166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02870262501893024\n",
      "Validation set loss: 0.026694840602524264\n",
      "Epoch 258\n",
      "Training set accuracy: 95.24166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028665530764789917\n",
      "Validation set loss: 0.026658545197644178\n",
      "Epoch 259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 95.24166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028628663924074278\n",
      "Validation set loss: 0.0266224738754637\n",
      "Epoch 260\n",
      "Training set accuracy: 95.24166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028592022242880693\n",
      "Validation set loss: 0.026586624385119925\n",
      "Epoch 261\n",
      "Training set accuracy: 95.24166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028555603497630314\n",
      "Validation set loss: 0.026550994506252572\n",
      "Epoch 262\n",
      "Training set accuracy: 95.24166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02851940549455844\n",
      "Validation set loss: 0.02651558204848792\n",
      "Epoch 263\n",
      "Training set accuracy: 95.24166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02848342606921162\n",
      "Validation set loss: 0.02648038485093261\n",
      "Epoch 264\n",
      "Training set accuracy: 95.25\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02844766308595674\n",
      "Validation set loss: 0.02644540078167853\n",
      "Epoch 265\n",
      "Training set accuracy: 95.25\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.0284121144375003\n",
      "Validation set loss: 0.02641062773731665\n",
      "Epoch 266\n",
      "Training set accuracy: 95.25\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028376778044415636\n",
      "Validation set loss: 0.0263760636424616\n",
      "Epoch 267\n",
      "Training set accuracy: 95.25\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028341651854681103\n",
      "Validation set loss: 0.026341706449284883\n",
      "Epoch 268\n",
      "Training set accuracy: 95.25\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028306733843226756\n",
      "Validation set loss: 0.026307554137057855\n",
      "Epoch 269\n",
      "Training set accuracy: 95.25\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02827202201149026\n",
      "Validation set loss: 0.0262736047117038\n",
      "Epoch 270\n",
      "Training set accuracy: 95.25\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028237514386981022\n",
      "Validation set loss: 0.026239856205358646\n",
      "Epoch 271\n",
      "Training set accuracy: 95.25\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028203209022854527\n",
      "Validation set loss: 0.02620630667594027\n",
      "Epoch 272\n",
      "Training set accuracy: 95.25\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02816910399749228\n",
      "Validation set loss: 0.026172954206726724\n",
      "Epoch 273\n",
      "Training set accuracy: 95.25833333333334\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02813519741409238\n",
      "Validation set loss: 0.02613979690594226\n",
      "Epoch 274\n",
      "Training set accuracy: 95.25\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.0281014874002675\n",
      "Validation set loss: 0.02610683290635142\n",
      "Epoch 275\n",
      "Training set accuracy: 95.25\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028067972107649525\n",
      "Validation set loss: 0.02607406036486154\n",
      "Epoch 276\n",
      "Training set accuracy: 95.25\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02803464971150367\n",
      "Validation set loss: 0.026041477462132517\n",
      "Epoch 277\n",
      "Training set accuracy: 95.25833333333334\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.028001518410348227\n",
      "Validation set loss: 0.026009082402194007\n",
      "Epoch 278\n",
      "Training set accuracy: 95.25833333333334\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02796857642558326\n",
      "Validation set loss: 0.02597687341207042\n",
      "Epoch 279\n",
      "Training set accuracy: 95.25833333333334\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027935822001125356\n",
      "Validation set loss: 0.025944848741412847\n",
      "Epoch 280\n",
      "Training set accuracy: 95.275\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027903253403048892\n",
      "Validation set loss: 0.025913006662138197\n",
      "Epoch 281\n",
      "Training set accuracy: 95.275\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027870868919236694\n",
      "Validation set loss: 0.02588134546807511\n",
      "Epoch 282\n",
      "Training set accuracy: 95.28333333333333\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02783866685903439\n",
      "Validation set loss: 0.02584986347461656\n",
      "Epoch 283\n",
      "Training set accuracy: 95.29166666666666\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.0278066455529115\n",
      "Validation set loss: 0.0258185590183789\n",
      "Epoch 284\n",
      "Training set accuracy: 95.29166666666666\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027774803352132192\n",
      "Validation set loss: 0.0257874304568682\n",
      "Epoch 285\n",
      "Training set accuracy: 95.3\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02774313862842852\n",
      "Validation set loss: 0.02575647616815156\n",
      "Epoch 286\n",
      "Training set accuracy: 95.3\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02771164977368135\n",
      "Validation set loss: 0.025725694550535767\n",
      "Epoch 287\n",
      "Training set accuracy: 95.30833333333332\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02768033519960729\n",
      "Validation set loss: 0.025695084022251114\n",
      "Epoch 288\n",
      "Training set accuracy: 95.325\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027649193337451035\n",
      "Validation set loss: 0.025664643021141853\n",
      "Epoch 289\n",
      "Training set accuracy: 95.325\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027618222637684316\n",
      "Validation set loss: 0.025634370004361806\n",
      "Epoch 290\n",
      "Training set accuracy: 95.325\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027587421569709\n",
      "Validation set loss: 0.025604263448075888\n",
      "Epoch 291\n",
      "Training set accuracy: 95.33333333333334\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027556788621567258\n",
      "Validation set loss: 0.02557432184716737\n",
      "Epoch 292\n",
      "Training set accuracy: 95.33333333333334\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02752632229965566\n",
      "Validation set loss: 0.02554454371495009\n",
      "Epoch 293\n",
      "Training set accuracy: 95.33333333333334\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027496021128445156\n",
      "Validation set loss: 0.02551492758288609\n",
      "Epoch 294\n",
      "Training set accuracy: 95.33333333333334\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027465883650207117\n",
      "Validation set loss: 0.025485472000308828\n",
      "Epoch 295\n",
      "Training set accuracy: 95.33333333333334\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027435908424741914\n",
      "Validation set loss: 0.025456175534151002\n",
      "Epoch 296\n",
      "Training set accuracy: 95.33333333333334\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02740609402911521\n",
      "Validation set loss: 0.025427036768677285\n",
      "Epoch 297\n",
      "Training set accuracy: 95.34166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027376439057397006\n",
      "Validation set loss: 0.02539805430522232\n",
      "Epoch 298\n",
      "Training set accuracy: 95.34166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027346942120407104\n",
      "Validation set loss: 0.025369226761933275\n",
      "Epoch 299\n",
      "Training set accuracy: 95.34166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027317601845463373\n",
      "Validation set loss: 0.025340552773516774\n",
      "Epoch 300\n",
      "Training set accuracy: 95.35\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.027288416876135046\n",
      "Validation set loss: 0.025312030990990827\n",
      "Epoch 301\n",
      "Training set accuracy: 95.35833333333333\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02725938587200234\n",
      "Validation set loss: 0.02528366008144101\n",
      "Epoch 302\n",
      "Training set accuracy: 95.36666666666666\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02723050750841737\n",
      "Validation set loss: 0.025255438727780768\n",
      "Epoch 303\n",
      "Training set accuracy: 95.36666666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.0272017804762712\n",
      "Validation set loss: 0.025227365628516716\n",
      "Epoch 304\n",
      "Training set accuracy: 95.36666666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02717320348176549\n",
      "Validation set loss: 0.02519943949751702\n",
      "Epoch 305\n",
      "Training set accuracy: 95.36666666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.027144775246185276\n",
      "Validation set loss: 0.02517165906378507\n",
      "Epoch 306\n",
      "Training set accuracy: 95.36666666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02711649450568022\n",
      "Validation set loss: 0.025144023071236\n",
      "Epoch 307\n",
      "Training set accuracy: 95.36666666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.027088360011045667\n",
      "Validation set loss: 0.025116530278478547\n",
      "Epoch 308\n",
      "Training set accuracy: 95.375\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.027060370527509557\n",
      "Validation set loss: 0.02508917945859901\n",
      "Epoch 309\n",
      "Training set accuracy: 95.375\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02703252483452252\n",
      "Validation set loss: 0.025061969398950692\n",
      "Epoch 310\n",
      "Training set accuracy: 95.38333333333333\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.027004821725552523\n",
      "Validation set loss: 0.02503489890094571\n",
      "Epoch 311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 95.38333333333333\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02697726000788124\n",
      "Validation set loss: 0.025007966779851343\n",
      "Epoch 312\n",
      "Training set accuracy: 95.39166666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026949838502405767\n",
      "Validation set loss: 0.0249811718645893\n",
      "Epoch 313\n",
      "Training set accuracy: 95.39166666666667\n",
      "Validation set accuracy: 96.1\n",
      "Training set loss: 0.026922556043443544\n",
      "Validation set loss: 0.024954512997538918\n",
      "Epoch 314\n",
      "Training set accuracy: 95.39999999999999\n",
      "Validation set accuracy: 96.1\n",
      "Training set loss: 0.02689541147853857\n",
      "Validation set loss: 0.024927989034343415\n",
      "Epoch 315\n",
      "Training set accuracy: 95.39999999999999\n",
      "Validation set accuracy: 96.1\n",
      "Training set loss: 0.02686840366827451\n",
      "Validation set loss: 0.024901598843719668\n",
      "Epoch 316\n",
      "Training set accuracy: 95.39999999999999\n",
      "Validation set accuracy: 96.1\n",
      "Training set loss: 0.02684153148608716\n",
      "Validation set loss: 0.024875341307271343\n",
      "Epoch 317\n",
      "Training set accuracy: 95.39999999999999\n",
      "Validation set accuracy: 96.1\n",
      "Training set loss: 0.026814793818083514\n",
      "Validation set loss: 0.024849215319304837\n",
      "Epoch 318\n",
      "Training set accuracy: 95.39999999999999\n",
      "Validation set accuracy: 96.1\n",
      "Training set loss: 0.02678818956286165\n",
      "Validation set loss: 0.02482321978664887\n",
      "Epoch 319\n",
      "Training set accuracy: 95.39999999999999\n",
      "Validation set accuracy: 96.1\n",
      "Training set loss: 0.02676171763133408\n",
      "Validation set loss: 0.024797353628476855\n",
      "Epoch 320\n",
      "Training set accuracy: 95.39999999999999\n",
      "Validation set accuracy: 96.1\n",
      "Training set loss: 0.02673537694655574\n",
      "Validation set loss: 0.0247716157761323\n",
      "Epoch 321\n",
      "Training set accuracy: 95.39999999999999\n",
      "Validation set accuracy: 96.1\n",
      "Training set loss: 0.026709166443552184\n",
      "Validation set loss: 0.024746005172957077\n",
      "Epoch 322\n",
      "Training set accuracy: 95.41666666666667\n",
      "Validation set accuracy: 96.1\n",
      "Training set loss: 0.026683085069152904\n",
      "Validation set loss: 0.02472052077412304\n",
      "Epoch 323\n",
      "Training set accuracy: 95.41666666666667\n",
      "Validation set accuracy: 96.1\n",
      "Training set loss: 0.02665713178182634\n",
      "Validation set loss: 0.02469516154646592\n",
      "Epoch 324\n",
      "Training set accuracy: 95.42500000000001\n",
      "Validation set accuracy: 96.1\n",
      "Training set loss: 0.02663130555151798\n",
      "Validation set loss: 0.02466992646832232\n",
      "Epoch 325\n",
      "Training set accuracy: 95.43333333333334\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026605605359491576\n",
      "Validation set loss: 0.024644814529369362\n",
      "Epoch 326\n",
      "Training set accuracy: 95.43333333333334\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026580030198171324\n",
      "Validation set loss: 0.024619824730466967\n",
      "Epoch 327\n",
      "Training set accuracy: 95.43333333333334\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026554579070989504\n",
      "Validation set loss: 0.02459495608350302\n",
      "Epoch 328\n",
      "Training set accuracy: 95.43333333333334\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026529250992233723\n",
      "Validation set loss: 0.024570207611240503\n",
      "Epoch 329\n",
      "Training set accuracy: 95.43333333333334\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026504044986898984\n",
      "Validation set loss: 0.02454557834716812\n",
      "Epoch 330\n",
      "Training set accuracy: 95.43333333333334\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026478960090540505\n",
      "Validation set loss: 0.024521067335352264\n",
      "Epoch 331\n",
      "Training set accuracy: 95.42500000000001\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02645399534912983\n",
      "Validation set loss: 0.024496673630292443\n",
      "Epoch 332\n",
      "Training set accuracy: 95.42500000000001\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02642914981891396\n",
      "Validation set loss: 0.02447239629677821\n",
      "Epoch 333\n",
      "Training set accuracy: 95.41666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02640442256627434\n",
      "Validation set loss: 0.02444823440974931\n",
      "Epoch 334\n",
      "Training set accuracy: 95.41666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026379812667591384\n",
      "Validation set loss: 0.024424187054157248\n",
      "Epoch 335\n",
      "Training set accuracy: 95.41666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026355319209108368\n",
      "Validation set loss: 0.024400253324829695\n",
      "Epoch 336\n",
      "Training set accuracy: 95.41666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02633094128679997\n",
      "Validation set loss: 0.024376432326336996\n",
      "Epoch 337\n",
      "Training set accuracy: 95.41666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02630667800624033\n",
      "Validation set loss: 0.024352723172860614\n",
      "Epoch 338\n",
      "Training set accuracy: 95.42500000000001\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026282528482475254\n",
      "Validation set loss: 0.024329124988063895\n",
      "Epoch 339\n",
      "Training set accuracy: 95.43333333333334\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026258491839896845\n",
      "Validation set loss: 0.024305636904965\n",
      "Epoch 340\n",
      "Training set accuracy: 95.43333333333334\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026234567212117203\n",
      "Validation set loss: 0.024282258065811555\n",
      "Epoch 341\n",
      "Training set accuracy: 95.44166666666666\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026210753741847545\n",
      "Validation set loss: 0.024258987621957682\n",
      "Epoch 342\n",
      "Training set accuracy: 95.44166666666666\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026187050580777003\n",
      "Validation set loss: 0.024235824733742653\n",
      "Epoch 343\n",
      "Training set accuracy: 95.44166666666666\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026163456889455056\n",
      "Validation set loss: 0.024212768570371808\n",
      "Epoch 344\n",
      "Training set accuracy: 95.44166666666666\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026139971837173776\n",
      "Validation set loss: 0.0241898183097991\n",
      "Epoch 345\n",
      "Training set accuracy: 95.43333333333334\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026116594601853577\n",
      "Validation set loss: 0.024166973138611735\n",
      "Epoch 346\n",
      "Training set accuracy: 95.43333333333334\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.0260933243699308\n",
      "Validation set loss: 0.024144232251916264\n",
      "Epoch 347\n",
      "Training set accuracy: 95.43333333333334\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026070160336245214\n",
      "Validation set loss: 0.02412159485322711\n",
      "Epoch 348\n",
      "Training set accuracy: 95.43333333333334\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.026047101703932204\n",
      "Validation set loss: 0.024099060154356068\n",
      "Epoch 349\n",
      "Training set accuracy: 95.43333333333334\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02602414768431402\n",
      "Validation set loss: 0.02407662737530407\n",
      "Epoch 350\n",
      "Training set accuracy: 95.43333333333334\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02600129749679358\n",
      "Validation set loss: 0.024054295744154706\n",
      "Epoch 351\n",
      "Training set accuracy: 95.42500000000001\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025978550368750707\n",
      "Validation set loss: 0.024032064496968875\n",
      "Epoch 352\n",
      "Training set accuracy: 95.42500000000001\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025955905535439434\n",
      "Validation set loss: 0.02400993287768176\n",
      "Epoch 353\n",
      "Training set accuracy: 95.42500000000001\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025933362239885984\n",
      "Validation set loss: 0.023987900138000638\n",
      "Epoch 354\n",
      "Training set accuracy: 95.44166666666666\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025910919732790166\n",
      "Validation set loss: 0.02396596553730506\n",
      "Epoch 355\n",
      "Training set accuracy: 95.44166666666666\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025888577272426144\n",
      "Validation set loss: 0.02394412834254798\n",
      "Epoch 356\n",
      "Training set accuracy: 95.44166666666666\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025866334124547762\n",
      "Validation set loss: 0.023922387828158698\n",
      "Epoch 357\n",
      "Training set accuracy: 95.45\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025844189562291092\n",
      "Validation set loss: 0.02390074327594739\n",
      "Epoch 358\n",
      "Training set accuracy: 95.45\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025822142866082528\n",
      "Validation set loss: 0.02387919397501053\n",
      "Epoch 359\n",
      "Training set accuracy: 95.45\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02580019332354614\n",
      "Validation set loss: 0.023857739221638665\n",
      "Epoch 360\n",
      "Training set accuracy: 95.45\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02577834022941227\n",
      "Validation set loss: 0.023836378319224544\n",
      "Epoch 361\n",
      "Training set accuracy: 95.45833333333333\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.0257565828854291\n",
      "Validation set loss: 0.02381511057817386\n",
      "Epoch 362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 95.45833333333333\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025734920600273763\n",
      "Validation set loss: 0.023793935315816018\n",
      "Epoch 363\n",
      "Training set accuracy: 95.45\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025713352689466017\n",
      "Validation set loss: 0.023772851856317424\n",
      "Epoch 364\n",
      "Training set accuracy: 95.45\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025691878475282898\n",
      "Validation set loss: 0.023751859530595235\n",
      "Epoch 365\n",
      "Training set accuracy: 95.45833333333333\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02567049728667429\n",
      "Validation set loss: 0.023730957676233077\n",
      "Epoch 366\n",
      "Training set accuracy: 95.46666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025649208459179746\n",
      "Validation set loss: 0.02371014563739738\n",
      "Epoch 367\n",
      "Training set accuracy: 95.46666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02562801133484824\n",
      "Validation set loss: 0.023689422764755563\n",
      "Epoch 368\n",
      "Training set accuracy: 95.46666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025606905262155172\n",
      "Validation set loss: 0.023668788415395024\n",
      "Epoch 369\n",
      "Training set accuracy: 95.46666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02558588959592662\n",
      "Validation set loss: 0.023648241952743506\n",
      "Epoch 370\n",
      "Training set accuracy: 95.46666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025564963697257432\n",
      "Validation set loss: 0.02362778274649064\n",
      "Epoch 371\n",
      "Training set accuracy: 95.46666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02554412693343759\n",
      "Validation set loss: 0.023607410172510633\n",
      "Epoch 372\n",
      "Training set accuracy: 95.46666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02552337867787464\n",
      "Validation set loss: 0.023587123612786233\n",
      "Epoch 373\n",
      "Training set accuracy: 95.46666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025502718310019077\n",
      "Validation set loss: 0.02356692245533342\n",
      "Epoch 374\n",
      "Training set accuracy: 95.46666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025482145215291734\n",
      "Validation set loss: 0.02354680609412772\n",
      "Epoch 375\n",
      "Training set accuracy: 95.46666666666667\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025461658785010534\n",
      "Validation set loss: 0.023526773929031252\n",
      "Epoch 376\n",
      "Training set accuracy: 95.48333333333333\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025441258416319366\n",
      "Validation set loss: 0.02350682536572106\n",
      "Epoch 377\n",
      "Training set accuracy: 95.50833333333333\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025420943512117464\n",
      "Validation set loss: 0.023486959815618144\n",
      "Epoch 378\n",
      "Training set accuracy: 95.5\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025400713480990135\n",
      "Validation set loss: 0.02346717669581808\n",
      "Epoch 379\n",
      "Training set accuracy: 95.50833333333333\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.02538056773714078\n",
      "Validation set loss: 0.023447475429022036\n",
      "Epoch 380\n",
      "Training set accuracy: 95.50833333333333\n",
      "Validation set accuracy: 96.0\n",
      "Training set loss: 0.025360505700322805\n",
      "Validation set loss: 0.02342785544346937\n",
      "Epoch 381\n",
      "Training set accuracy: 95.50833333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.025340526795774417\n",
      "Validation set loss: 0.023408316172870716\n",
      "Epoch 382\n",
      "Training set accuracy: 95.51666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.025320630454151147\n",
      "Validation set loss: 0.02338885705634226\n",
      "Epoch 383\n",
      "Training set accuracy: 95.51666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.025300816111463648\n",
      "Validation set loss: 0.023369477538341118\n",
      "Epoch 384\n",
      "Training set accuracy: 95.51666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.025281083209012924\n",
      "Validation set loss: 0.02335017706860125\n",
      "Epoch 385\n",
      "Training set accuracy: 95.51666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.025261431193327608\n",
      "Validation set loss: 0.023330955102070734\n",
      "Epoch 386\n",
      "Training set accuracy: 95.51666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.025241859516102225\n",
      "Validation set loss: 0.023311811098849514\n",
      "Epoch 387\n",
      "Training set accuracy: 95.525\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02522236763413684\n",
      "Validation set loss: 0.023292744524128342\n",
      "Epoch 388\n",
      "Training set accuracy: 95.525\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02520295500927688\n",
      "Validation set loss: 0.023273754848128533\n",
      "Epoch 389\n",
      "Training set accuracy: 95.53333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.025183621108352972\n",
      "Validation set loss: 0.02325484154604236\n",
      "Epoch 390\n",
      "Training set accuracy: 95.53333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.025164365403124004\n",
      "Validation set loss: 0.023236004097974716\n",
      "Epoch 391\n",
      "Training set accuracy: 95.53333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.025145187370219237\n",
      "Validation set loss: 0.023217241988885102\n",
      "Epoch 392\n",
      "Training set accuracy: 95.53333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02512608649108047\n",
      "Validation set loss: 0.023198554708530883\n",
      "Epoch 393\n",
      "Training set accuracy: 95.53333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.025107062251907793\n",
      "Validation set loss: 0.023179941751411\n",
      "Epoch 394\n",
      "Training set accuracy: 95.53333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02508811414360296\n",
      "Validation set loss: 0.023161402616710618\n",
      "Epoch 395\n",
      "Training set accuracy: 95.53333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.025069241661716608\n",
      "Validation set loss: 0.02314293680824664\n",
      "Epoch 396\n",
      "Training set accuracy: 95.54166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.025050444306392583\n",
      "Validation set loss: 0.023124543834413834\n",
      "Epoch 397\n",
      "Training set accuracy: 95.54166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02503172158231744\n",
      "Validation set loss: 0.02310622320813178\n",
      "Epoch 398\n",
      "Training set accuracy: 95.525\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.025013072998666275\n",
      "Validation set loss: 0.02308797444679242\n",
      "Epoch 399\n",
      "Training set accuracy: 95.525\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02499449806905236\n",
      "Validation set loss: 0.02306979707220853\n",
      "Epoch 400\n",
      "Training set accuracy: 95.525\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02497599631147642\n",
      "Validation set loss: 0.02305169061056311\n",
      "Epoch 401\n",
      "Training set accuracy: 95.53333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024957567248276295\n",
      "Validation set loss: 0.02303365459235848\n",
      "Epoch 402\n",
      "Training set accuracy: 95.54166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024939210406077723\n",
      "Validation set loss: 0.023015688552367727\n",
      "Epoch 403\n",
      "Training set accuracy: 95.54166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02492092531574602\n",
      "Validation set loss: 0.022997792029584904\n",
      "Epoch 404\n",
      "Training set accuracy: 95.55\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024902711512337517\n",
      "Validation set loss: 0.022979964567177782\n",
      "Epoch 405\n",
      "Training set accuracy: 95.55\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024884568535052394\n",
      "Validation set loss: 0.022962205712439662\n",
      "Epoch 406\n",
      "Training set accuracy: 95.55833333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024866495927188977\n",
      "Validation set loss: 0.02294451501674306\n",
      "Epoch 407\n",
      "Training set accuracy: 95.55833333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024848493236095684\n",
      "Validation set loss: 0.02292689203549292\n",
      "Epoch 408\n",
      "Training set accuracy: 95.55833333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024830560013127695\n",
      "Validation set loss: 0.022909336328081804\n",
      "Epoch 409\n",
      "Training set accuracy: 95.55833333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024812695813601005\n",
      "Validation set loss: 0.022891847457844137\n",
      "Epoch 410\n",
      "Training set accuracy: 95.55833333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024794900196747963\n",
      "Validation set loss: 0.022874424992012487\n",
      "Epoch 411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 95.55833333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024777172725674628\n",
      "Validation set loss: 0.02285706850167339\n",
      "Epoch 412\n",
      "Training set accuracy: 95.56666666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02475951296731731\n",
      "Validation set loss: 0.02283977756172446\n",
      "Epoch 413\n",
      "Training set accuracy: 95.56666666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02474192049239959\n",
      "Validation set loss: 0.022822551750831713\n",
      "Epoch 414\n",
      "Training set accuracy: 95.56666666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024724394875391534\n",
      "Validation set loss: 0.022805390651387522\n",
      "Epoch 415\n",
      "Training set accuracy: 95.56666666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02470693569446691\n",
      "Validation set loss: 0.022788293849469135\n",
      "Epoch 416\n",
      "Training set accuracy: 95.56666666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02468954253146388\n",
      "Validation set loss: 0.022771260934797945\n",
      "Epoch 417\n",
      "Training set accuracy: 95.56666666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024672214971843572\n",
      "Validation set loss: 0.02275429150069895\n",
      "Epoch 418\n",
      "Training set accuracy: 95.58333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02465495260465197\n",
      "Validation set loss: 0.02273738514406106\n",
      "Epoch 419\n",
      "Training set accuracy: 95.58333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02463775502247839\n",
      "Validation set loss: 0.022720541465297825\n",
      "Epoch 420\n",
      "Training set accuracy: 95.58333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024620621821418907\n",
      "Validation set loss: 0.0227037600683085\n",
      "Epoch 421\n",
      "Training set accuracy: 95.58333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024603552601037176\n",
      "Validation set loss: 0.02268704056044003\n",
      "Epoch 422\n",
      "Training set accuracy: 95.59166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024586546964326383\n",
      "Validation set loss: 0.022670382552449117\n",
      "Epoch 423\n",
      "Training set accuracy: 95.6\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02456960451767384\n",
      "Validation set loss: 0.022653785658465018\n",
      "Epoch 424\n",
      "Training set accuracy: 95.6\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02455272487082271\n",
      "Validation set loss: 0.02263724949595284\n",
      "Epoch 425\n",
      "Training set accuracy: 95.6\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.0245359076368358\n",
      "Validation set loss: 0.02262077368567707\n",
      "Epoch 426\n",
      "Training set accuracy: 95.6\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024519152432060924\n",
      "Validation set loss: 0.022604357851666045\n",
      "Epoch 427\n",
      "Training set accuracy: 95.625\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02450245887609439\n",
      "Validation set loss: 0.02258800162117635\n",
      "Epoch 428\n",
      "Training set accuracy: 95.625\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024485826591747195\n",
      "Validation set loss: 0.022571704624658094\n",
      "Epoch 429\n",
      "Training set accuracy: 95.625\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024469255205010507\n",
      "Validation set loss: 0.022555466495720326\n",
      "Epoch 430\n",
      "Training set accuracy: 95.625\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024452744345020806\n",
      "Validation set loss: 0.02253928687109729\n",
      "Epoch 431\n",
      "Training set accuracy: 95.63333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024436293644027583\n",
      "Validation set loss: 0.02252316539061453\n",
      "Epoch 432\n",
      "Training set accuracy: 95.63333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02441990273735992\n",
      "Validation set loss: 0.022507101697156136\n",
      "Epoch 433\n",
      "Training set accuracy: 95.63333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024403571263393407\n",
      "Validation set loss: 0.02249109543663182\n",
      "Epoch 434\n",
      "Training set accuracy: 95.63333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.0243872988635184\n",
      "Validation set loss: 0.022475146257944577\n",
      "Epoch 435\n",
      "Training set accuracy: 95.625\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02437108518210796\n",
      "Validation set loss: 0.02245925381295929\n",
      "Epoch 436\n",
      "Training set accuracy: 95.625\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024354929866487372\n",
      "Validation set loss: 0.022443417756470605\n",
      "Epoch 437\n",
      "Training set accuracy: 95.625\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02433883256690084\n",
      "Validation set loss: 0.022427637746172357\n",
      "Epoch 438\n",
      "Training set accuracy: 95.625\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024322792936483883\n",
      "Validation set loss: 0.022411913442626795\n",
      "Epoch 439\n",
      "Training set accuracy: 95.625\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024306810631230885\n",
      "Validation set loss: 0.022396244509234275\n",
      "Epoch 440\n",
      "Training set accuracy: 95.625\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02429088530996619\n",
      "Validation set loss: 0.022380630612203384\n",
      "Epoch 441\n",
      "Training set accuracy: 95.625\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024275016634314226\n",
      "Validation set loss: 0.022365071420521444\n",
      "Epoch 442\n",
      "Training set accuracy: 95.63333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02425920426867101\n",
      "Validation set loss: 0.02234956660592551\n",
      "Epoch 443\n",
      "Training set accuracy: 95.63333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02424344788017477\n",
      "Validation set loss: 0.022334115842873276\n",
      "Epoch 444\n",
      "Training set accuracy: 95.64166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024227747138678063\n",
      "Validation set loss: 0.022318718808515048\n",
      "Epoch 445\n",
      "Training set accuracy: 95.64166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024212101716719184\n",
      "Validation set loss: 0.022303375182665397\n",
      "Epoch 446\n",
      "Training set accuracy: 95.64166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02419651128949529\n",
      "Validation set loss: 0.022288084647775624\n",
      "Epoch 447\n",
      "Training set accuracy: 95.64166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02418097553483445\n",
      "Validation set loss: 0.022272846888906454\n",
      "Epoch 448\n",
      "Training set accuracy: 95.65\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024165494133168597\n",
      "Validation set loss: 0.0222576615937008\n",
      "Epoch 449\n",
      "Training set accuracy: 95.65\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024150066767507538\n",
      "Validation set loss: 0.022242528452357246\n",
      "Epoch 450\n",
      "Training set accuracy: 95.65\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024134693123411842\n",
      "Validation set loss: 0.022227447157603792\n",
      "Epoch 451\n",
      "Training set accuracy: 95.65\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024119372888967764\n",
      "Validation set loss: 0.02221241740467162\n",
      "Epoch 452\n",
      "Training set accuracy: 95.65\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024104105754760696\n",
      "Validation set loss: 0.022197438891269582\n",
      "Epoch 453\n",
      "Training set accuracy: 95.65\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024088891413849935\n",
      "Validation set loss: 0.022182511317558485\n",
      "Epoch 454\n",
      "Training set accuracy: 95.65\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024073729561743955\n",
      "Validation set loss: 0.02216763438612668\n",
      "Epoch 455\n",
      "Training set accuracy: 95.65\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024058619896375817\n",
      "Validation set loss: 0.022152807801964554\n",
      "Epoch 456\n",
      "Training set accuracy: 95.65833333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02404356211807792\n",
      "Validation set loss: 0.0221380312724406\n",
      "Epoch 457\n",
      "Training set accuracy: 95.65833333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024028555929558854\n",
      "Validation set loss: 0.022123304507276946\n",
      "Epoch 458\n",
      "Training set accuracy: 95.66666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.024013601035878768\n",
      "Validation set loss: 0.02210862721852572\n",
      "Epoch 459\n",
      "Training set accuracy: 95.675\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02399869714442624\n",
      "Validation set loss: 0.02209399912054522\n",
      "Epoch 460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 95.68333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02398384396489441\n",
      "Validation set loss: 0.022079419929977008\n",
      "Epoch 461\n",
      "Training set accuracy: 95.68333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023969041209259554\n",
      "Validation set loss: 0.022064889365722453\n",
      "Epoch 462\n",
      "Training set accuracy: 95.68333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02395428859175549\n",
      "Validation set loss: 0.022050407148920335\n",
      "Epoch 463\n",
      "Training set accuracy: 95.68333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023939585828854536\n",
      "Validation set loss: 0.02203597300292431\n",
      "Epoch 464\n",
      "Training set accuracy: 95.68333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02392493263924222\n",
      "Validation set loss: 0.022021586653280564\n",
      "Epoch 465\n",
      "Training set accuracy: 95.68333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023910328743797934\n",
      "Validation set loss: 0.02200724782770618\n",
      "Epoch 466\n",
      "Training set accuracy: 95.68333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02389577386557172\n",
      "Validation set loss: 0.021992956256067283\n",
      "Epoch 467\n",
      "Training set accuracy: 95.68333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023881267729762796\n",
      "Validation set loss: 0.021978711670357726\n",
      "Epoch 468\n",
      "Training set accuracy: 95.68333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02386681006369948\n",
      "Validation set loss: 0.021964513804677947\n",
      "Epoch 469\n",
      "Training set accuracy: 95.68333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023852400596817674\n",
      "Validation set loss: 0.02195036239521403\n",
      "Epoch 470\n",
      "Training set accuracy: 95.68333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02383803906064018\n",
      "Validation set loss: 0.021936257180217113\n",
      "Epoch 471\n",
      "Training set accuracy: 95.68333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02382372518875594\n",
      "Validation set loss: 0.02192219789998307\n",
      "Epoch 472\n",
      "Training set accuracy: 95.68333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02380945871680104\n",
      "Validation set loss: 0.02190818429683213\n",
      "Epoch 473\n",
      "Training set accuracy: 95.69166666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02379523938243772\n",
      "Validation set loss: 0.021894216115089477\n",
      "Epoch 474\n",
      "Training set accuracy: 95.69166666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02378106692533502\n",
      "Validation set loss: 0.021880293101064777\n",
      "Epoch 475\n",
      "Training set accuracy: 95.69166666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023766941087149177\n",
      "Validation set loss: 0.02186641500303345\n",
      "Epoch 476\n",
      "Training set accuracy: 95.7\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02375286161150486\n",
      "Validation set loss: 0.02185258157121711\n",
      "Epoch 477\n",
      "Training set accuracy: 95.7\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023738828243975302\n",
      "Validation set loss: 0.021838792557764754\n",
      "Epoch 478\n",
      "Training set accuracy: 95.7\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023724840732065208\n",
      "Validation set loss: 0.021825047716733856\n",
      "Epoch 479\n",
      "Training set accuracy: 95.7\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02371089882518947\n",
      "Validation set loss: 0.02181134680407175\n",
      "Epoch 480\n",
      "Training set accuracy: 95.7\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023697002274657777\n",
      "Validation set loss: 0.0217976895775975\n",
      "Epoch 481\n",
      "Training set accuracy: 95.71666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023683150833654333\n",
      "Validation set loss: 0.021784075796983746\n",
      "Epoch 482\n",
      "Training set accuracy: 95.70833333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023669344257220795\n",
      "Validation set loss: 0.021770505223738672\n",
      "Epoch 483\n",
      "Training set accuracy: 95.70833333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023655582302238572\n",
      "Validation set loss: 0.021756977621188417\n",
      "Epoch 484\n",
      "Training set accuracy: 95.71666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023641864727411088\n",
      "Validation set loss: 0.021743492754459585\n",
      "Epoch 485\n",
      "Training set accuracy: 95.72500000000001\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.0236281912932463\n",
      "Validation set loss: 0.0217300503904619\n",
      "Epoch 486\n",
      "Training set accuracy: 95.72500000000001\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023614561762040482\n",
      "Validation set loss: 0.021716650297871017\n",
      "Epoch 487\n",
      "Training set accuracy: 95.72500000000001\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02360097589786008\n",
      "Validation set loss: 0.021703292247112035\n",
      "Epoch 488\n",
      "Training set accuracy: 95.71666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02358743346652602\n",
      "Validation set loss: 0.02168997601034214\n",
      "Epoch 489\n",
      "Training set accuracy: 95.71666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023573934235595936\n",
      "Validation set loss: 0.02167670136143478\n",
      "Epoch 490\n",
      "Training set accuracy: 95.71666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023560477974349334\n",
      "Validation set loss: 0.021663468075962904\n",
      "Epoch 491\n",
      "Training set accuracy: 95.71666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02354706445377047\n",
      "Validation set loss: 0.021650275931182916\n",
      "Epoch 492\n",
      "Training set accuracy: 95.71666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023533693446532614\n",
      "Validation set loss: 0.021637124706018803\n",
      "Epoch 493\n",
      "Training set accuracy: 95.72500000000001\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.0235203647269818\n",
      "Validation set loss: 0.021624014181046352\n",
      "Epoch 494\n",
      "Training set accuracy: 95.72500000000001\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02350707807112228\n",
      "Validation set loss: 0.02161094413847763\n",
      "Epoch 495\n",
      "Training set accuracy: 95.73333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023493833256600056\n",
      "Validation set loss: 0.021597914362145202\n",
      "Epoch 496\n",
      "Training set accuracy: 95.73333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023480630062688124\n",
      "Validation set loss: 0.021584924637487436\n",
      "Epoch 497\n",
      "Training set accuracy: 95.73333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023467468270270814\n",
      "Validation set loss: 0.021571974751533184\n",
      "Epoch 498\n",
      "Training set accuracy: 95.73333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02345434766182985\n",
      "Validation set loss: 0.021559064492886748\n",
      "Epoch 499\n",
      "Training set accuracy: 95.73333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023441268021428707\n",
      "Validation set loss: 0.021546193651713324\n",
      "Epoch 500\n",
      "Training set accuracy: 95.73333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023428229134698362\n",
      "Validation set loss: 0.021533362019724413\n",
      "Epoch 501\n",
      "Training set accuracy: 95.73333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02341523078882283\n",
      "Validation set loss: 0.021520569390163436\n",
      "Epoch 502\n",
      "Training set accuracy: 95.73333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023402272772524522\n",
      "Validation set loss: 0.02150781555779141\n",
      "Epoch 503\n",
      "Training set accuracy: 95.73333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.0233893548760511\n",
      "Validation set loss: 0.021495100318873025\n",
      "Epoch 504\n",
      "Training set accuracy: 95.74166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023376476891160364\n",
      "Validation set loss: 0.021482423471162602\n",
      "Epoch 505\n",
      "Training set accuracy: 95.74166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02336363861110732\n",
      "Validation set loss: 0.021469784813890263\n",
      "Epoch 506\n",
      "Training set accuracy: 95.75\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023350839830629633\n",
      "Validation set loss: 0.02145718414774855\n",
      "Epoch 507\n",
      "Training set accuracy: 95.75\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023338080345935593\n",
      "Validation set loss: 0.021444621274878724\n",
      "Epoch 508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 95.75\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023325359954688797\n",
      "Validation set loss: 0.02143209599885761\n",
      "Epoch 509\n",
      "Training set accuracy: 95.75833333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02331267845599644\n",
      "Validation set loss: 0.021419608124684294\n",
      "Epoch 510\n",
      "Training set accuracy: 95.75833333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023300035650396074\n",
      "Validation set loss: 0.021407157458767274\n",
      "Epoch 511\n",
      "Training set accuracy: 95.75833333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023287431339841888\n",
      "Validation set loss: 0.021394743808911428\n",
      "Epoch 512\n",
      "Training set accuracy: 95.76666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023274865327692747\n",
      "Validation set loss: 0.021382366984305318\n",
      "Epoch 513\n",
      "Training set accuracy: 95.76666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02326233741869892\n",
      "Validation set loss: 0.021370026795508656\n",
      "Epoch 514\n",
      "Training set accuracy: 95.76666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023249847418990256\n",
      "Validation set loss: 0.02135772305443972\n",
      "Epoch 515\n",
      "Training set accuracy: 95.75833333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02323739513606327\n",
      "Validation set loss: 0.02134545557436328\n",
      "Epoch 516\n",
      "Training set accuracy: 95.75833333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023224980378769022\n",
      "Validation set loss: 0.021333224169878047\n",
      "Epoch 517\n",
      "Training set accuracy: 95.76666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023212602957301185\n",
      "Validation set loss: 0.021321028656904984\n",
      "Epoch 518\n",
      "Training set accuracy: 95.76666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023200262683183894\n",
      "Validation set loss: 0.021308868852675026\n",
      "Epoch 519\n",
      "Training set accuracy: 95.76666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02318795936926023\n",
      "Validation set loss: 0.021296744575717574\n",
      "Epoch 520\n",
      "Training set accuracy: 95.76666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02317569282967991\n",
      "Validation set loss: 0.021284655645848784\n",
      "Epoch 521\n",
      "Training set accuracy: 95.76666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02316346287988791\n",
      "Validation set loss: 0.02127260188415976\n",
      "Epoch 522\n",
      "Training set accuracy: 95.76666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023151269336613968\n",
      "Validation set loss: 0.021260583113005545\n",
      "Epoch 523\n",
      "Training set accuracy: 95.76666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023139112017859495\n",
      "Validation set loss: 0.02124859915599352\n",
      "Epoch 524\n",
      "Training set accuracy: 95.76666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02312699074288742\n",
      "Validation set loss: 0.021236649837972344\n",
      "Epoch 525\n",
      "Training set accuracy: 95.76666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023114905332211413\n",
      "Validation set loss: 0.021224734985020855\n",
      "Epoch 526\n",
      "Training set accuracy: 95.76666666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023102855607584256\n",
      "Validation set loss: 0.021212854424437218\n",
      "Epoch 527\n",
      "Training set accuracy: 95.775\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02309084139198685\n",
      "Validation set loss: 0.021201007984728057\n",
      "Epoch 528\n",
      "Training set accuracy: 95.775\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023078862509617555\n",
      "Validation set loss: 0.021189195495597692\n",
      "Epoch 529\n",
      "Training set accuracy: 95.775\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02306691878588248\n",
      "Validation set loss: 0.02117741678793767\n",
      "Epoch 530\n",
      "Training set accuracy: 95.78333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023055010047383608\n",
      "Validation set loss: 0.021165671693816147\n",
      "Epoch 531\n",
      "Training set accuracy: 95.78333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023043136121909433\n",
      "Validation set loss: 0.021153960046467784\n",
      "Epoch 532\n",
      "Training set accuracy: 95.78333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02303129683842368\n",
      "Validation set loss: 0.021142281680283075\n",
      "Epoch 533\n",
      "Training set accuracy: 95.78333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023019492027056113\n",
      "Validation set loss: 0.02113063643079864\n",
      "Epoch 534\n",
      "Training set accuracy: 95.78333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.023007721519092007\n",
      "Validation set loss: 0.021119024134686942\n",
      "Epoch 535\n",
      "Training set accuracy: 95.78333333333333\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022995985146961564\n",
      "Validation set loss: 0.021107444629746258\n",
      "Epoch 536\n",
      "Training set accuracy: 95.79166666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022984282744231158\n",
      "Validation set loss: 0.021095897754891138\n",
      "Epoch 537\n",
      "Training set accuracy: 95.79166666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022972614145592922\n",
      "Validation set loss: 0.021084383350142497\n",
      "Epoch 538\n",
      "Training set accuracy: 95.79166666666666\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02296097918685468\n",
      "Validation set loss: 0.021072901256618006\n",
      "Epoch 539\n",
      "Training set accuracy: 95.8\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02294937770493145\n",
      "Validation set loss: 0.0210614513165226\n",
      "Epoch 540\n",
      "Training set accuracy: 95.8\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02293780953783484\n",
      "Validation set loss: 0.021050033373139074\n",
      "Epoch 541\n",
      "Training set accuracy: 95.80833333333332\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022926274524664517\n",
      "Validation set loss: 0.021038647270818594\n",
      "Epoch 542\n",
      "Training set accuracy: 95.80833333333332\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02291477250559874\n",
      "Validation set loss: 0.021027292854971763\n",
      "Epoch 543\n",
      "Training set accuracy: 95.80833333333332\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022903303321884134\n",
      "Validation set loss: 0.02101596997205921\n",
      "Epoch 544\n",
      "Training set accuracy: 95.80833333333332\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02289186681582863\n",
      "Validation set loss: 0.021004678469582757\n",
      "Epoch 545\n",
      "Training set accuracy: 95.80833333333332\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022880462830790652\n",
      "Validation set loss: 0.02099341819607626\n",
      "Epoch 546\n",
      "Training set accuracy: 95.80833333333332\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.0228690912111713\n",
      "Validation set loss: 0.020982189001097058\n",
      "Epoch 547\n",
      "Training set accuracy: 95.80833333333332\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022857751802404274\n",
      "Validation set loss: 0.020970990735216924\n",
      "Epoch 548\n",
      "Training set accuracy: 95.8\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02284644445094896\n",
      "Validation set loss: 0.02095982325001346\n",
      "Epoch 549\n",
      "Training set accuracy: 95.8\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022835169004280453\n",
      "Validation set loss: 0.020948686398061682\n",
      "Epoch 550\n",
      "Training set accuracy: 95.8\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022823925310881146\n",
      "Validation set loss: 0.020937580032925337\n",
      "Epoch 551\n",
      "Training set accuracy: 95.80833333333332\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02281271322023303\n",
      "Validation set loss: 0.020926504009148524\n",
      "Epoch 552\n",
      "Training set accuracy: 95.81666666666668\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022801532582808523\n",
      "Validation set loss: 0.02091545818224763\n",
      "Epoch 553\n",
      "Training set accuracy: 95.81666666666668\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02279038325006194\n",
      "Validation set loss: 0.020904442408702612\n",
      "Epoch 554\n",
      "Training set accuracy: 95.81666666666668\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022779265074422742\n",
      "Validation set loss: 0.020893456545949315\n",
      "Epoch 555\n",
      "Training set accuracy: 95.81666666666668\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022768177909285953\n",
      "Validation set loss: 0.020882500452371104\n",
      "Epoch 556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 95.81666666666668\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02275712160900449\n",
      "Validation set loss: 0.02087157398729094\n",
      "Epoch 557\n",
      "Training set accuracy: 95.81666666666668\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022746096028881942\n",
      "Validation set loss: 0.020860677010963745\n",
      "Epoch 558\n",
      "Training set accuracy: 95.81666666666668\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02273510102516345\n",
      "Validation set loss: 0.02084980938456806\n",
      "Epoch 559\n",
      "Training set accuracy: 95.81666666666668\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02272413645502881\n",
      "Validation set loss: 0.020838970970198805\n",
      "Epoch 560\n",
      "Training set accuracy: 95.81666666666668\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022713202176584277\n",
      "Validation set loss: 0.020828161630859196\n",
      "Epoch 561\n",
      "Training set accuracy: 95.81666666666668\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022702298048855908\n",
      "Validation set loss: 0.020817381230453565\n",
      "Epoch 562\n",
      "Training set accuracy: 95.81666666666668\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022691423931780322\n",
      "Validation set loss: 0.020806629633779467\n",
      "Epoch 563\n",
      "Training set accuracy: 95.81666666666668\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022680579686198462\n",
      "Validation set loss: 0.020795906706520508\n",
      "Epoch 564\n",
      "Training set accuracy: 95.83333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022669765173847993\n",
      "Validation set loss: 0.02078521231523886\n",
      "Epoch 565\n",
      "Training set accuracy: 95.83333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022658980257355372\n",
      "Validation set loss: 0.020774546327367867\n",
      "Epoch 566\n",
      "Training set accuracy: 95.83333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02264822480022917\n",
      "Validation set loss: 0.020763908611205167\n",
      "Epoch 567\n",
      "Training set accuracy: 95.83333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02263749866685276\n",
      "Validation set loss: 0.020753299035905177\n",
      "Epoch 568\n",
      "Training set accuracy: 95.83333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022626801722477042\n",
      "Validation set loss: 0.02074271747147213\n",
      "Epoch 569\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022616133833213696\n",
      "Validation set loss: 0.020732163788753307\n",
      "Epoch 570\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02260549486602719\n",
      "Validation set loss: 0.02072163785943177\n",
      "Epoch 571\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02259488468872944\n",
      "Validation set loss: 0.020711139556019564\n",
      "Epoch 572\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022584303169971794\n",
      "Validation set loss: 0.0207006687518512\n",
      "Epoch 573\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022573750179238468\n",
      "Validation set loss: 0.020690225321076436\n",
      "Epoch 574\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02256322558684017\n",
      "Validation set loss: 0.0206798091386542\n",
      "Epoch 575\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022552729263906873\n",
      "Validation set loss: 0.0206694200803454\n",
      "Epoch 576\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.022542261082382168\n",
      "Validation set loss: 0.020659058022706882\n",
      "Epoch 577\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.022531820915015113\n",
      "Validation set loss: 0.02064872284308458\n",
      "Epoch 578\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.022521408635355906\n",
      "Validation set loss: 0.020638414419607332\n",
      "Epoch 579\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02251102411774773\n",
      "Validation set loss: 0.020628132631180546\n",
      "Epoch 580\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02250066723732104\n",
      "Validation set loss: 0.020617877357479775\n",
      "Epoch 581\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.022490337869987484\n",
      "Validation set loss: 0.020607648478944588\n",
      "Epoch 582\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.8\n",
      "Training set loss: 0.02248003589243358\n",
      "Validation set loss: 0.020597445876772345\n",
      "Epoch 583\n",
      "Training set accuracy: 95.84166666666667\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02246976118211415\n",
      "Validation set loss: 0.020587269432912246\n",
      "Epoch 584\n",
      "Training set accuracy: 95.83333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022459513617246803\n",
      "Validation set loss: 0.02057711903005912\n",
      "Epoch 585\n",
      "Training set accuracy: 95.83333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02244929307680583\n",
      "Validation set loss: 0.020566994551647524\n",
      "Epoch 586\n",
      "Training set accuracy: 95.825\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.0224390994405152\n",
      "Validation set loss: 0.02055689588184587\n",
      "Epoch 587\n",
      "Training set accuracy: 95.825\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022428932588844493\n",
      "Validation set loss: 0.020546822905550276\n",
      "Epoch 588\n",
      "Training set accuracy: 95.825\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02241879240300166\n",
      "Validation set loss: 0.020536775508379224\n",
      "Epoch 589\n",
      "Training set accuracy: 95.825\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02240867876492713\n",
      "Validation set loss: 0.02052675357666744\n",
      "Epoch 590\n",
      "Training set accuracy: 95.825\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02239859155728897\n",
      "Validation set loss: 0.020516756997460226\n",
      "Epoch 591\n",
      "Training set accuracy: 95.825\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022388530663476767\n",
      "Validation set loss: 0.020506785658508\n",
      "Epoch 592\n",
      "Training set accuracy: 95.825\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.0223784959675951\n",
      "Validation set loss: 0.020496839448260487\n",
      "Epoch 593\n",
      "Training set accuracy: 95.83333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.022368487354459888\n",
      "Validation set loss: 0.02048691825586146\n",
      "Epoch 594\n",
      "Training set accuracy: 95.83333333333334\n",
      "Validation set accuracy: 95.89999999999999\n",
      "Training set loss: 0.02235850470959112\n",
      "Validation set loss: 0.020477021971142935\n"
     ]
    }
   ],
   "source": [
    "epoch, accuracy_training, accuracy_validation, loss_training, loss_validation, mse_train_list, mse_val_list = logistic_regression(trainxs, trainys, devxs, devys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ce17ea5748>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.axis([-10, epoch, min(loss_training) - 0.005, max(loss_training)])\n",
    "plt.plot(loss_training, label='training set loss')\n",
    "#plt.plot(loss_validation, label='validation set loss', color='r')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ce17cad470>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.axis([-10, epoch, min(accuracy_training), max(accuracy_training) + 5])\n",
    "plt.plot(accuracy_training, label='training set accuracy')\n",
    "#plt.plot(accuracy_validation, label='validation set accuracy', color='r')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch = 313\n",
      "Accuracy on training set = 95.39166666666667\n",
      "Accuracy on validation set = 96.1\n"
     ]
    }
   ],
   "source": [
    "ind = accuracy_validation.index(max(accuracy_validation))\n",
    "print(\"Best epoch =\", ind)\n",
    "print(\"Accuracy on training set =\", accuracy_training[ind])\n",
    "print(\"Accuracy on validation set =\", accuracy_validation[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse training loss:  [0.125, 0.11758031575658488, 0.11214173444297776, 0.10732754581143035, 0.1030600759226863, 0.09927988984547187, 0.09592490463979349, 0.09293625800817144, 0.09026113728526274, 0.08785367163428165, 0.08567478400541657, 0.08369155407878745, 0.08187640814059816, 0.08020630157100056, 0.07866197101512377, 0.0772272845873897, 0.07588869358033219, 0.07463477770364599, 0.07345587160436155, 0.07234375973883139, 0.0712914276258896, 0.07029285908435216, 0.06934287074019445, 0.0684369766498912, 0.06757127724051365, 0.0667423678985644, 0.06594726346415969, 0.06518333563280893, 0.06444826086361156, 0.06373997686792161, 0.0630566461303648, 0.06239662521441951, 0.06175843884370647, 0.061140757940567274, 0.06054238095565273, 0.05996221794413642, 0.05939927694213525, 0.05885265227592158, 0.058321514500441964, 0.05780510171557862, 0.05730271205090916, 0.05681369714433806, 0.056337456468393915, 0.055873432381400114, 0.055421105800084, 0.05497999240624542, 0.05454963931346797, 0.05412962213101156, 0.05371954237136597, 0.05331902515578989, 0.052927717178766744, 0.052545284897887255, 0.0521714129203913, 0.05180580256160965, 0.0514481705539548, 0.05109824788801574, 0.05075577876979386, 0.05042051968024134, 0.050092238525084765, 0.04977071386448192, 0.049455734213405655, 0.0491470974048094, 0.04884461000863067, 0.04854808680055477, 0.04825735027521095, 0.04797223019912286, 0.04769256319929993, 0.0474181923838468, 0.04714896699139472, 0.04688474206653142, 0.046625378158730614, 0.04637074104256601, 0.04612070145724334, 0.04587513486370123, 0.04563392121772255, 0.04539694475766576, 0.04516409380557267, 0.04493526058053927, 0.04471034102335053, 0.044489234631480905, 0.044271844303652115, 0.04405807619321829, 0.043847839569719126, 0.04364104668800382, 0.04343761266438393, 0.0432374553593227, 0.043040495266212266, 0.04284665540582972, 0.04265586122609804, 0.0424680405068092, 0.04228312326899581, 0.04210104168866222, 0.04192173001460967, 0.041745124490110405, 0.0415711632782045, 0.04139978639041016, 0.041230935618653486, 0.041064554470237824, 0.04090058810568546, 0.040738983279296065, 0.040579688282276705, 0.0404226528883083, 0.04026782830142194, 0.04011516710606673, 0.03996462321925845, 0.039816151844705015, 0.039669709428811324, 0.0395252536184717, 0.03938274322056384, 0.03924213816306292, 0.03910339945769952, 0.03896648916408918, 0.03883137035526533, 0.03869800708455137, 0.038566364353711066, 0.03843640808231951, 0.038308105078300375, 0.0381814230095776, 0.03805633037679268, 0.037932796487040996, 0.0378107914285833, 0.037690286046490155, 0.0375712519191799, 0.03745366133581208, 0.0373374872745004, 0.03722270338131115, 0.03710928395001428, 0.03699720390255615, 0.03688643877022453, 0.03677696467547754, 0.03666875831440957, 0.03656179693982881, 0.03645605834492166, 0.03635152084748082, 0.03624816327467469, 0.036145964948336946, 0.036044905670755654, 0.035944965710942814, 0.03584612579136547, 0.03574836707512085, 0.035651671153538234]\n",
      "our training loss:  [0.125, 0.11758031575658512, 0.11214173444297793, 0.10732754581143014, 0.10306007592268579, 0.09927988984547208, 0.09592490463979352, 0.0929362580081717, 0.0902611372852629, 0.08785367163428134, 0.08567478400541671, 0.08369155407878724, 0.0818764081405981, 0.08020630157100075, 0.07866197101512375, 0.07722728458738945, 0.0758886935803323, 0.07463477770364603, 0.0734558716043612, 0.0723437597388314, 0.07129142762588983, 0.07029285908435193, 0.06934287074019424, 0.06843697664989146, 0.06757127724051348, 0.0667423678985644, 0.06594726346415997, 0.06518333563280897, 0.06444826086361165, 0.0637399768679215, 0.06305664613036494, 0.06239662521441962, 0.061758438843706465, 0.06114075794056741, 0.060542380955652654, 0.059962217944136746, 0.05939927694213521, 0.058852652275921465, 0.05832151450044215, 0.05780510171557851, 0.057302712050909414, 0.05681369714433756, 0.056337456468394026, 0.0558734323814001, 0.055421105800083886, 0.054979992406245126, 0.054549639313467804, 0.054129622131011586, 0.05371954237136595, 0.05331902515578989, 0.052927717178766834, 0.05254528489788719, 0.05217141292039123, 0.051805802561609375, 0.05144817055395493, 0.05109824788801593, 0.05075577876979362, 0.05042051968024159, 0.05009223852508463, 0.04977071386448217, 0.049455734213405614, 0.049147097404809374, 0.048844610008630523, 0.04854808680055468, 0.04825735027521111, 0.047972230199122855, 0.047692563199299785, 0.0474181923838468, 0.047148966991394606, 0.04688474206653121, 0.04662537815873107, 0.04637074104256597, 0.04612070145724365, 0.04587513486370123, 0.04563392121772232, 0.04539694475766571, 0.04516409380557257, 0.044935260580539156, 0.044710341023350635, 0.04448923463148083, 0.044271844303652205, 0.044058076193218325, 0.04384783956971939, 0.043641046688003976, 0.04343761266438396, 0.04323745535932294, 0.043040495266212245, 0.04284665540582978, 0.04265586122609797, 0.04246804050680911, 0.042283123268995755, 0.042101041688662355, 0.04192173001460975, 0.04174512449011039, 0.04157116327820449, 0.04139978639040998, 0.04123093561865332, 0.04106455447023792, 0.04090058810568557, 0.04073898327929591, 0.0405796882822766, 0.04042265288830813, 0.040267828301421844, 0.04011516710606669, 0.039964623219258415, 0.03981615184470492, 0.039669709428811324, 0.039525253618471624, 0.039382743220563766, 0.03924213816306276, 0.03910339945769961, 0.03896648916408931, 0.038831370355265286, 0.03869800708455145, 0.03856636435371123, 0.03843640808231943, 0.03830810507830037, 0.03818142300957764, 0.03805633037679264, 0.03793279648704122, 0.037810791428583235, 0.037690286046490065, 0.0375712519191799, 0.03745366133581185, 0.0373374872745004, 0.03722270338131106, 0.03710928395001411, 0.03699720390255625, 0.03688643877022461, 0.03677696467547752, 0.03666875831440941, 0.036561796939828826, 0.03645605834492165, 0.03635152084748116, 0.036248163274674665, 0.036145964948336815, 0.036044905670755606, 0.035944965710942745, 0.03584612579136552, 0.03574836707512063, 0.035651671153538365]\n"
     ]
    }
   ],
   "source": [
    "print(\"mse training loss: \", mse_train_list)\n",
    "print(\"our training loss: \", loss_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse val loss:  [0.11715526461237132, 0.11166747791745217, 0.10685128822965703, 0.10257258197945782, 0.09876912731742038, 0.09538216917298459, 0.09235575045133314, 0.08963916553053879, 0.08718804628863795, 0.08496438531543044, 0.08293602219731278, 0.08107592122327409, 0.0793614164475059, 0.07777350848691052, 0.07629624660415588, 0.07491620324667636, 0.07362203569088274, 0.07240412439839543, 0.07125427646638352, 0.0701654831283722, 0.06913172156509377, 0.06814779277680115, 0.0672091886956367, 0.06631198297624831, 0.06545274096736219, 0.06462844524415982, 0.06383643379308493, 0.06307434851302389, 0.06234009215458694, 0.061631792184448975, 0.06094777035288512, 0.0602865169749052, 0.059646669120946266, 0.05902699206163895, 0.05842636343041237, 0.0578437596637106, 0.057278244356139284, 0.056728958230703966, 0.05619511047540724, 0.05567597123917611, 0.055170865114243677, 0.05467916546017451, 0.0542002894478653, 0.05373369372099861, 0.053278870588319906, 0.05283534467334194, 0.05240266995913237, 0.05198042717510043, 0.05156822148047536, 0.05116568040572191, 0.05077245201867049, 0.05038820328682412, 0.05001261861127952, 0.04964539851107983, 0.0492862584396988, 0.04893492771781642, 0.04859114856865245, 0.04825467524392899, 0.04792527323008441, 0.04760271852569394, 0.047286796982202305, 0.04697730370106486, 0.04667404248125165, 0.04637682531181068, 0.04608547190482967, 0.04579980926469469, 0.04551967129002878, 0.04524489840511704, 0.04497533721799208, 0.04471084020267628, 0.04445126540335758, 0.044196476158521604, 0.043946340843278975, 0.04370073262831518, 0.04345952925405714, 0.04322261281879672, 0.042989869579640495, 0.04276118976526884, 0.04253646739958823, 0.042315600135449556, 0.04209848909768433, 0.04188503873478075, 0.041675156678584326, 0.04146875361146277, 0.04126574314042515, 0.041066041677729, 0.04086956832754953, 0.040676244778319985, 0.0404859952003847, 0.04029874614863509, 0.04011442646982465, 0.03993296721428276, 0.03975430155176802, 0.039578364691221585, 0.03940509380419773, 0.03923442795176544, 0.03906630801468911, 0.03890067662670934, 0.03873747811075743, 0.03857665841794792, 0.03841816506920378, 0.03826194709937813, 0.03810795500374511, 0.03795614068674034, 0.037806457412838744, 0.037658859759464175, 0.03751330357183186, 0.037369745919629965, 0.03722814505545272, 0.03708846037490158, 0.03695065237827652, 0.03681468263378332, 0.036680513742186886, 0.03654810930284452, 0.03641743388105662, 0.03628845297667531, 0.03616113299391511, 0.03603544121231221, 0.035911345758781785, 0.03578881558072561, 0.03566782042014418, 0.035548330788710274, 0.0354303179437627, 0.03531375386518123, 0.035198611233105324, 0.03508486340646158, 0.03497248440226577, 0.03486144887566769, 0.034751732100708026, 0.034643309951758246, 0.03453615888561546, 0.03443025592422601, 0.03432557863801228, 0.03422210512977865, 0.03411981401917354, 0.03401868442768551, 0.03391869596415234, 0.03381982871076306, 0.03372206320953374, 0.03362538044923849, 0.03352976185277839]\n",
      "pour val loss:  [0.11715526461237143, 0.11166747791745214, 0.10685128822965706, 0.10257258197945789, 0.09876912731742027, 0.09538216917298471, 0.0923557504513331, 0.08963916553053887, 0.08718804628863794, 0.08496438531543041, 0.08293602219731289, 0.08107592122327405, 0.07936141644750591, 0.07777350848691052, 0.07629624660415578, 0.07491620324667636, 0.07362203569088265, 0.07240412439839536, 0.07125427646638344, 0.07016548312837216, 0.06913172156509372, 0.0681477927768012, 0.06720918869563675, 0.06631198297624827, 0.06545274096736219, 0.06462844524415984, 0.06383643379308487, 0.06307434851302392, 0.062340092154586926, 0.06163179218444902, 0.060947770352885094, 0.06028651697490514, 0.059646669120946356, 0.059026992061638923, 0.058426363430412374, 0.0578437596637105, 0.05727824435613924, 0.05672895823070404, 0.056195110475407276, 0.0556759712391761, 0.05517086511424367, 0.05467916546017443, 0.054200289447865306, 0.05373369372099871, 0.053278870588319927, 0.0528353446733419, 0.05240266995913238, 0.0519804271751004, 0.05156822148047535, 0.05116568040572193, 0.05077245201867048, 0.05038820328682428, 0.05001261861127951, 0.04964539851107987, 0.04928625843969877, 0.04893492771781643, 0.04859114856865239, 0.048254675243929006, 0.04792527323008434, 0.047602718525693886, 0.047286796982202346, 0.04697730370106485, 0.046674042481251746, 0.04637682531181064, 0.04608547190482959, 0.045799809264694735, 0.04551967129002873, 0.04524489840511704, 0.04497533721799208, 0.0447108402026763, 0.044451265403357546, 0.04419647615852156, 0.04394634084327889, 0.04370073262831513, 0.043459529254057154, 0.0432226128187967, 0.042989869579640475, 0.04276118976526884, 0.04253646739958819, 0.04231560013544957, 0.04209848909768437, 0.041885038734780736, 0.04167515667858432, 0.04146875361146278, 0.04126574314042514, 0.041066041677729016, 0.040869568327549476, 0.04067624477832005, 0.040485995200384615, 0.04029874614863513, 0.04011442646982465, 0.03993296721428274, 0.03975430155176804, 0.039578364691221564, 0.03940509380419776, 0.0392344279517654, 0.039066308014689126, 0.038900676626709346, 0.03873747811075741, 0.0385766584179479, 0.03841816506920379, 0.03826194709937816, 0.03810795500374512, 0.037956140686740365, 0.03780645741283868, 0.03765885975946416, 0.037513303571831864, 0.03736974591963003, 0.037228145055452765, 0.037088460374901565, 0.0369506523782765, 0.03681468263378332, 0.03668051374218687, 0.03654810930284444, 0.03641743388105663, 0.03628845297667525, 0.03616113299391512, 0.03603544121231225, 0.03591134575878179, 0.03578881558072558, 0.035667820420144145, 0.03554833078871026, 0.035430317943762654, 0.03531375386518123, 0.03519861123310531, 0.03508486340646157, 0.034972484402265726, 0.03486144887566769, 0.03475173210070795, 0.03464330995175828, 0.03453615888561548, 0.03443025592422602, 0.03432557863801229, 0.034222105129778586, 0.03411981401917354, 0.03401868442768549, 0.03391869596415235, 0.03381982871076305, 0.03372206320953371, 0.03362538044923851, 0.03352976185277841]\n"
     ]
    }
   ],
   "source": [
    "print(\"mse val loss: \", mse_val_list)\n",
    "print(\"pour val loss: \", loss_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(w, b):\n",
    "    toflatten = (w, [b])\n",
    "    vec = np.zeros(sum(len(x) for x in toflatten))\n",
    "    offset = 0\n",
    "    for parameter in toflatten:\n",
    "        vec[offset:offset + len(parameter)] = parameter\n",
    "        offset += len(parameter)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unflatten(w, b, vec):\n",
    "    tounflatten = (w, [b])\n",
    "    offset = 0\n",
    "    for parameter in tounflatten:\n",
    "        parameter[:] = vec[offset:offset + len(parameter)]\n",
    "        offset += len(parameter)\n",
    "    return tounflatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdfprime(w, b, x, y):\n",
    "    epsilon  = 0.000001\n",
    "    grad_w = np.zeros_like(w)\n",
    "    grad_b = 0.0\n",
    "    vecm     = flatten(w, b)\n",
    "    vecgradm = flatten(grad_w, grad_b)\n",
    "    \n",
    "    for i in range(len(vecm)):\n",
    "        wi           = vecm[i]\n",
    "\n",
    "        vecm[i]     += epsilon/2       \n",
    "        w_j, b_j     = unflatten(grad_w, grad_b, vecm)\n",
    "        r            = loss(y, f(x, w_j, b_j))\n",
    "        vecm[i]      = wi\n",
    "        vecm[i]     -= epsilon/2\n",
    "        w_j, b_j     = unflatten(grad_w, grad_b, vecm)\n",
    "        l            = loss(y, f(x, w_j, b_j))\n",
    "        vecgradm[i]  = (r - l)/epsilon\n",
    "\n",
    "        vecm[i]      = wi\n",
    "\n",
    "    return unflatten(grad_w, grad_b, vecgradm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fprime(n, x, y, w, b):\n",
    "    grad_w = np.zeros(n)\n",
    "    grad_b = 0.0\n",
    "    \n",
    "    #Forward pass\n",
    "    z = np.dot(w, x) + b\n",
    "    y_hat = logistic_func(z)\n",
    "    \n",
    "    #Backward pass\n",
    "    grad_z = (y_hat - y) * logistic_der(z)\n",
    "    grad_w += x * (y_hat - y) * (1 - y_hat) * y_hat \n",
    "    grad_b += (y_hat - y) * (1 - y_hat) * y_hat\n",
    "    \n",
    "    return (grad_w, [grad_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trainxs[0]\n",
    "y = trainys[0]\n",
    "w = np.random.random(784) / 100\n",
    "grad_w, grad_b = fprime(trainxs.shape[1], x, y, w, 0.0)\n",
    "fd_grad_w, fd_grad_b = fdfprime(w, 0.0, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.59789976e-11]\n",
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.59590674e-11  3.97840649e-11\n",
      " -1.33445893e-11 -3.15701632e-11 -4.45147114e-11  4.06184669e-11\n",
      " -3.02197156e-11 -3.20861948e-11 -3.65328046e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -7.31815997e-11 -3.53031215e-11 -9.42288053e-11\n",
      " -8.89477936e-11  4.88099838e-12  1.73095149e-11 -9.42288053e-11\n",
      " -7.65192631e-11  1.91759802e-11  1.24917271e-10  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  7.73880265e-11  2.54890692e-11  7.36550820e-11\n",
      "  6.12265516e-11 -8.23163065e-11 -8.23163065e-11  6.12265516e-11\n",
      " -8.23163065e-11  6.12265516e-11  5.93600724e-11 -7.63985195e-11\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  8.61392901e-12 -1.33445893e-11 -4.45147114e-11\n",
      " -4.45147114e-11 -4.21322144e-11 -4.21322144e-11  4.87980351e-11\n",
      "  8.61392901e-12 -4.21322144e-11  6.12265516e-11  5.51775986e-12\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -3.53031215e-11 -3.20861948e-11 -3.20861948e-11\n",
      " -8.23163065e-11 -8.23163065e-11 -3.20861948e-11 -4.45147114e-11\n",
      "  1.24917271e-10 -1.43209056e-12  4.06184669e-11 -2.70028028e-11\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  7.77951314e-12  5.54294943e-11  4.87980351e-11\n",
      " -4.45147114e-11 -3.15701632e-11  8.61392901e-12  4.87980351e-11\n",
      "  1.24917271e-10  8.61392901e-12 -9.10119063e-11 -2.70028028e-11\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -3.87945544e-11 -5.53951607e-11  5.06645143e-11  7.36550820e-11\n",
      "  6.12265516e-11  8.09791123e-12  5.93600724e-11 -4.63811906e-11\n",
      "  2.92220137e-11  2.15584772e-11 -2.01736960e-11 -3.56983887e-11\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -1.08413417e-11  5.85256704e-11  7.36550820e-11  6.12265516e-11\n",
      " -8.23163065e-11  2.30085395e-12 -4.63811906e-11 -3.53031215e-11\n",
      "  7.26348148e-12  1.91759802e-11 -9.52608825e-11  4.36377531e-11\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  4.86003945e-11 -3.53031215e-11  8.09791123e-12  8.61392901e-12\n",
      "  2.05264278e-11  2.05264278e-11  4.88099838e-12  1.59590674e-11\n",
      " -5.53951607e-11  1.91759802e-11  5.06645143e-11  2.25136507e-11\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.58364613e-11  5.61431734e-11 -9.52608825e-11 -3.15701632e-11\n",
      " -1.01057926e-10  7.26348148e-12 -2.84740009e-11 -1.09874276e-10\n",
      " -2.52570881e-11 -4.63811906e-11 -9.42288053e-11 -2.77164749e-11\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -5.71408823e-11 -4.72156203e-11 -4.21322144e-11  8.09791123e-12\n",
      " -1.19941557e-11  4.17712878e-11  4.34388636e-13  4.28802271e-11\n",
      " -3.53031215e-11 -4.63811906e-11  8.09791123e-12  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -5.08278003e-11 -4.53491411e-11 -1.14781240e-11  2.30085395e-12\n",
      "  2.15584772e-11  0.00000000e+00  4.41537779e-11 -5.04325193e-11\n",
      " -3.53031215e-11 -3.29856975e-12 -3.02197156e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -1.01057926e-10  1.24082841e-10 -8.23163065e-11  5.06645143e-11\n",
      "  5.06645143e-11  0.00000000e+00  0.00000000e+00 -5.28150301e-11\n",
      "  5.61431734e-11 -7.65192631e-11  4.24849461e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -5.08278003e-11  7.77951314e-12 -4.45147114e-11  5.93600724e-11\n",
      "  1.50477686e-11  0.00000000e+00  0.00000000e+00  7.81016918e-11\n",
      "  6.67052247e-11 -7.65192631e-11 -4.84453033e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  1.78482229e-12 -2.52570881e-11  1.24917271e-10 -1.29131900e-10\n",
      "  3.01771767e-11  0.00000000e+00  0.00000000e+00  4.34388636e-13\n",
      " -1.89440130e-11 -3.29856975e-12 -4.89613211e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  4.87980351e-11 -1.28285577e-11  2.92220137e-11  2.73555345e-11\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.30085395e-12\n",
      " -4.13298562e-12 -1.09039833e-10 -5.71408823e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -9.10119063e-11  4.88099838e-12  1.91759802e-11 -3.53031215e-11\n",
      " -5.75795314e-12  0.00000000e+00  0.00000000e+00 -3.65328046e-11\n",
      " -6.51546872e-12  1.73095149e-11 -2.70028028e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  5.55125390e-13 -5.99945094e-12  1.91759802e-11 -9.42288053e-11\n",
      " -8.97486946e-12  0.00000000e+00  0.00000000e+00 -5.20574972e-11\n",
      " -1.89440130e-11  2.73555345e-11 -3.65328046e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.27497402e-10 -8.89477936e-11 -9.42288053e-11\n",
      "  4.86003945e-11  0.00000000e+00  0.00000000e+00  5.99968616e-11\n",
      " -1.89440130e-11 -1.33445893e-11 -3.12517928e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -1.09039833e-10 -3.53031215e-11 -3.29856975e-12\n",
      " -1.19941557e-11  0.00000000e+00  0.00000000e+00 -3.65328046e-11\n",
      " -6.51546872e-12  3.97840649e-11 -1.69567763e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -4.89613211e-11  1.83415783e-11 -1.09039833e-10\n",
      "  7.26348148e-12  0.00000000e+00  0.00000000e+00 -1.25101735e-11\n",
      " -1.89440130e-11  3.97840649e-11 -3.56983887e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -2.05689753e-11 -4.64901728e-12 -1.28285577e-11\n",
      " -4.13298562e-12 -8.13611539e-11  0.00000000e+00  4.06184669e-11\n",
      "  3.41846551e-11  3.97840649e-11 -1.08413417e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -8.89477936e-11  7.77951314e-12\n",
      "  7.26348148e-12 -2.77164749e-11  0.00000000e+00 -4.45147114e-11\n",
      " -5.67456082e-11 -3.29856975e-12 -5.20574972e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.24917271e-10  4.84796508e-11\n",
      "  2.54890692e-11  2.06471819e-11  0.00000000e+00  7.81016918e-11\n",
      " -1.89440130e-11 -9.42288053e-11 -6.02370549e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -6.70661582e-11  0.00000000e+00 -4.70948627e-11  4.84796508e-11\n",
      "  1.83415783e-11 -2.70028028e-11  0.00000000e+00 -4.13298562e-12\n",
      " -5.67456082e-11 -3.29856975e-12 -8.13611539e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.24676276e-11  8.91797747e-11\n",
      "  5.85256704e-11 -2.52570881e-11  0.00000000e+00  1.27497402e-10\n",
      "  4.84796508e-11  8.61392901e-12  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.54890692e-11\n",
      "  6.67052247e-11 -7.65192631e-11  0.00000000e+00 -2.52570881e-11\n",
      "  4.04656864e-12  2.23929070e-11  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -9.10119063e-11\n",
      " -4.72156203e-11 -5.71408823e-11  0.00000000e+00 -4.45147114e-11\n",
      "  4.84796508e-11  2.79923168e-11  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "Max difference for w: 1.2749740152528943e-10\n"
     ]
    }
   ],
   "source": [
    "fd_b = np.subtract(fd_grad_b,grad_b)\n",
    "fd_w = np.subtract(fd_grad_w,grad_w)\n",
    "max_fd = fd_w.max()\n",
    "print(fd_b)\n",
    "print(fd_w)\n",
    "print(\"Max difference for w:\", max_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
