{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "plt.set_cmap(\"gray\") # Otherwise grayscale images look purple\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TarFile.close of <tarfile.TarFile object at 0x00000120BCA5AD30>>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://udon.stacken.kth.se/~ninjin/comp0090_assignment_1_data.tar.gz'\n",
    "ftpstream = urllib.request.urlopen(url)\n",
    "tar = tarfile.open(fileobj=ftpstream, mode=\"r|gz\")\n",
    "tar.extractall()\n",
    "tar.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainxs = np.load(\"comp0090_assignment_1_data/fashion-train-imgs.npz\").transpose((2, 1, 0))\n",
    "trainys = np.load(\"comp0090_assignment_1_data/fashion-train-labels.npz\")\n",
    "devxs   = np.load(\"comp0090_assignment_1_data/fashion-dev-imgs.npz\").transpose((2, 1, 0))\n",
    "devys   = np.load(\"comp0090_assignment_1_data/fashion-dev-labels.npz\")\n",
    "testxs  = np.load(\"comp0090_assignment_1_data/fashion-test-imgs.npz\").transpose((2, 1, 0))\n",
    "testys  = np.load(\"comp0090_assignment_1_data/fashion-test-labels.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 28, 28)\n",
      "(12000,)\n",
      "(1000, 28, 28)\n",
      "(1000,)\n",
      "(1000, 28, 28)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(trainxs.shape)\n",
    "print(trainys.shape)\n",
    "print(devxs.shape)\n",
    "print(devys.shape)\n",
    "print(testxs.shape)\n",
    "print(testys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(4,4)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axarr[i, j].imshow(trainxs[np.random.randint(0, len(trainxs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data to make it easier to work with\n",
    "trainxs = trainxs.reshape(-1, 784)\n",
    "devxs = devxs.reshape(-1, 784)\n",
    "testxs = testxs.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create weight and sum parameters for the algorithm\n",
    "def initialise_parameters(xs):\n",
    "    w = np.zeros(xs.shape[1])\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_func(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def logistic_der(x):\n",
    "    return logistic_func(x) * (1 - logistic_func(x))\n",
    "\n",
    "def f(x, w, b):\n",
    "    return logistic_func(np.dot(w, x) + b)\n",
    "\n",
    "def p(x, w, b):\n",
    "    if f(x, w, b) >= 0.5:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure Accuracy\n",
    "\n",
    "def accuracy(xs, ys, w, b):\n",
    "    correct = 0\n",
    "    for i in range(xs.shape[0]):\n",
    "        if p(xs[i], w, b) == ys[i]:\n",
    "            correct += 1\n",
    "    return correct/len(xs)*100    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Function\n",
    "\n",
    "def loss_func(ys, y_predict):\n",
    "    sum = 0\n",
    "    n = ys.shape[0]\n",
    "    for i in range(n):\n",
    "        sum += (ys[i] - y_predict[i]) ** 2\n",
    "    return 1/2*n*sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Function for single points\n",
    "\n",
    "def loss(y, y_hat):\n",
    "    return ((y - y_hat) ** 2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_predictions(devxs, devys, w, b):\n",
    "    y_predict = []\n",
    "    \n",
    "    for i in range(devxs.shape[0]):\n",
    "        y_hat = f(devxs[i], w, b)\n",
    "        y_predict.append(y_hat)\n",
    "        \n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(trainxs, trainys, devxs, devys):\n",
    "    w, b = initialise_parameters(trainxs)\n",
    "    \n",
    "    accuracy_training = []\n",
    "    accuracy_validation = []\n",
    "    \n",
    "    # store predicted y's and loss for each epoch\n",
    "    y_predict = []\n",
    "    loss_training = []\n",
    "    loss_validation = []\n",
    "    \n",
    "    # store old accuracy and consecutive epochs count to detect convergence\n",
    "    loss_old = loss_func(devys, validation_predictions(devxs, devys, w, b))\n",
    "    row_epoch = 0\n",
    "    \n",
    "    # store number of epochs to have a nice graph\n",
    "    epoch = 0\n",
    "    learning_rate = 0.1\n",
    "    \n",
    "    while True:\n",
    "        print('Epoch', epoch)\n",
    "        trainxs, trainys = shuffle(trainxs, trainys)\n",
    "        grad_w, grad_b = initialise_parameters(trainxs)\n",
    "        y_predict = []\n",
    "\n",
    "        for i in range(trainxs.shape[0]):\n",
    "            y_hat = f(trainxs[i], w, b)\n",
    "            y_predict.append(y_hat)\n",
    "            grad_w += trainxs[i] * (y_hat - trainys[i]) * (1 - y_hat) * y_hat \n",
    "            grad_b += (y_hat - trainys[i]) * (1 - y_hat) * y_hat \n",
    "\n",
    "        grad_w /= trainxs.shape[0]\n",
    "        grad_b /= trainxs.shape[0]\n",
    "        w -= learning_rate * grad_w\n",
    "        b -= learning_rate * grad_b\n",
    "\n",
    "        accuracy_train = accuracy(trainxs, trainys, w, b)\n",
    "        accuracy_training.append(accuracy_train)\n",
    "        print('Training set accuracy:', accuracy(trainxs, trainys, w, b))\n",
    "        accuracy_dev = accuracy(devxs, devys, w, b)\n",
    "        accuracy_validation.append(accuracy_dev)\n",
    "        print('Validation set accuracy:', accuracy_dev)\n",
    "        \n",
    "        loss_train = loss_func(trainys, y_predict)\n",
    "        loss_training.append(loss_train)\n",
    "        print('Training set loss:', loss_train)\n",
    "        loss_dev = loss_func(devys, validation_predictions(devxs, devys, w, b))\n",
    "        loss_validation.append(loss_dev)\n",
    "        print('Validation set loss:', loss_dev)\n",
    "        \n",
    "        # check if converged\n",
    "        if np.abs(loss_dev - loss_old) < 100:\n",
    "            row_epoch += 1\n",
    "            if row_epoch == 5:\n",
    "                break\n",
    "        else:\n",
    "            row_epoch = 0\n",
    "            \n",
    "        loss_old = loss_dev\n",
    "        epoch += 1\n",
    "    \n",
    "    return epoch, accuracy_training, accuracy_validation, loss_training, loss_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training set accuracy: 55.95833333333333\n",
      "Validation set accuracy: 56.89999999999999\n",
      "Training set loss: 18000000.0\n",
      "Validation set loss: 117155.2646123714\n",
      "Epoch 1\n",
      "Training set accuracy: 66.4\n",
      "Validation set accuracy: 68.4\n",
      "Training set loss: 16931565.468948156\n",
      "Validation set loss: 111667.47791745214\n",
      "Epoch 2\n",
      "Training set accuracy: 71.98333333333333\n",
      "Validation set accuracy: 71.89999999999999\n",
      "Training set loss: 16148409.759788807\n",
      "Validation set loss: 106851.28822965706\n",
      "Epoch 3\n",
      "Training set accuracy: 76.40833333333333\n",
      "Validation set accuracy: 76.2\n",
      "Training set loss: 15455166.59684593\n",
      "Validation set loss: 102572.5819794579\n",
      "Epoch 4\n",
      "Training set accuracy: 78.34166666666667\n",
      "Validation set accuracy: 78.8\n",
      "Training set loss: 14840650.932866774\n",
      "Validation set loss: 98769.12731742027\n",
      "Epoch 5\n",
      "Training set accuracy: 79.48333333333333\n",
      "Validation set accuracy: 80.2\n",
      "Training set loss: 14296304.137747979\n",
      "Validation set loss: 95382.16917298472\n",
      "Epoch 6\n",
      "Training set accuracy: 80.15\n",
      "Validation set accuracy: 80.7\n",
      "Training set loss: 13813186.268130263\n",
      "Validation set loss: 92355.7504513331\n",
      "Epoch 7\n",
      "Training set accuracy: 80.48333333333333\n",
      "Validation set accuracy: 81.10000000000001\n",
      "Training set loss: 13382821.153176637\n",
      "Validation set loss: 89639.16553053887\n",
      "Epoch 8\n",
      "Training set accuracy: 80.80833333333334\n",
      "Validation set accuracy: 81.6\n",
      "Training set loss: 12997603.76907783\n",
      "Validation set loss: 87188.04628863794\n",
      "Epoch 9\n",
      "Training set accuracy: 81.10833333333333\n",
      "Validation set accuracy: 81.89999999999999\n",
      "Training set loss: 12650928.715336543\n",
      "Validation set loss: 84964.3853154304\n",
      "Epoch 10\n",
      "Training set accuracy: 81.15833333333333\n",
      "Validation set accuracy: 82.19999999999999\n",
      "Training set loss: 12337168.89678002\n",
      "Validation set loss: 82936.02219731285\n",
      "Epoch 11\n",
      "Training set accuracy: 81.34166666666667\n",
      "Validation set accuracy: 82.0\n",
      "Training set loss: 12051583.787345363\n",
      "Validation set loss: 81075.92122327405\n",
      "Epoch 12\n",
      "Training set accuracy: 81.475\n",
      "Validation set accuracy: 82.1\n",
      "Training set loss: 11790202.77224612\n",
      "Validation set loss: 79361.41644750592\n",
      "Epoch 13\n",
      "Training set accuracy: 81.64166666666667\n",
      "Validation set accuracy: 82.19999999999999\n",
      "Training set loss: 11549707.426224114\n",
      "Validation set loss: 77773.50848691052\n",
      "Epoch 14\n",
      "Training set accuracy: 81.675\n",
      "Validation set accuracy: 82.3\n",
      "Training set loss: 11327323.826177895\n",
      "Validation set loss: 76296.24660415578\n",
      "Epoch 15\n",
      "Training set accuracy: 81.875\n",
      "Validation set accuracy: 82.5\n",
      "Training set loss: 11120728.980584115\n",
      "Validation set loss: 74916.20324667636\n",
      "Epoch 16\n",
      "Training set accuracy: 82.03333333333333\n",
      "Validation set accuracy: 82.89999999999999\n",
      "Training set loss: 10927971.875567837\n",
      "Validation set loss: 73622.03569088264\n",
      "Epoch 17\n",
      "Training set accuracy: 82.21666666666667\n",
      "Validation set accuracy: 83.0\n",
      "Training set loss: 10747407.989324966\n",
      "Validation set loss: 72404.12439839535\n",
      "Epoch 18\n",
      "Training set accuracy: 82.425\n",
      "Validation set accuracy: 83.3\n",
      "Training set loss: 10577645.511028057\n",
      "Validation set loss: 71254.27646638342\n",
      "Epoch 19\n",
      "Training set accuracy: 82.53333333333333\n",
      "Validation set accuracy: 83.7\n",
      "Training set loss: 10417501.402391741\n",
      "Validation set loss: 70165.48312837216\n",
      "Epoch 20\n",
      "Training set accuracy: 82.825\n",
      "Validation set accuracy: 84.5\n",
      "Training set loss: 10265965.578128153\n",
      "Validation set loss: 69131.72156509371\n",
      "Epoch 21\n",
      "Training set accuracy: 83.075\n",
      "Validation set accuracy: 84.8\n",
      "Training set loss: 10122171.70814668\n",
      "Validation set loss: 68147.7927768012\n",
      "Epoch 22\n",
      "Training set accuracy: 83.25833333333334\n",
      "Validation set accuracy: 85.0\n",
      "Training set loss: 9985373.386587985\n",
      "Validation set loss: 67209.18869563672\n",
      "Epoch 23\n",
      "Training set accuracy: 83.46666666666667\n",
      "Validation set accuracy: 85.2\n",
      "Training set loss: 9854924.637584375\n",
      "Validation set loss: 66311.98297624825\n",
      "Epoch 24\n",
      "Training set accuracy: 83.7\n",
      "Validation set accuracy: 85.7\n",
      "Training set loss: 9730263.922633944\n",
      "Validation set loss: 65452.74096736217\n",
      "Epoch 25\n",
      "Training set accuracy: 84.0\n",
      "Validation set accuracy: 86.0\n",
      "Training set loss: 9610900.977393292\n",
      "Validation set loss: 64628.44524415983\n",
      "Epoch 26\n",
      "Training set accuracy: 84.21666666666667\n",
      "Validation set accuracy: 86.2\n",
      "Training set loss: 9496405.938838983\n",
      "Validation set loss: 63836.433793084885\n",
      "Epoch 27\n",
      "Training set accuracy: 84.43333333333334\n",
      "Validation set accuracy: 86.5\n",
      "Training set loss: 9386400.331124458\n",
      "Validation set loss: 63074.348513023906\n",
      "Epoch 28\n",
      "Training set accuracy: 84.775\n",
      "Validation set accuracy: 86.8\n",
      "Training set loss: 9280549.564360093\n",
      "Validation set loss: 62340.09215458692\n",
      "Epoch 29\n",
      "Training set accuracy: 85.02499999999999\n",
      "Validation set accuracy: 87.4\n",
      "Training set loss: 9178556.668980714\n",
      "Validation set loss: 61631.79218444902\n",
      "Epoch 30\n",
      "Training set accuracy: 85.36666666666667\n",
      "Validation set accuracy: 87.7\n",
      "Training set loss: 9080157.042772533\n",
      "Validation set loss: 60947.77035288509\n",
      "Epoch 31\n",
      "Training set accuracy: 85.65833333333333\n",
      "Validation set accuracy: 88.2\n",
      "Training set loss: 8985114.030876415\n",
      "Validation set loss: 60286.51697490514\n",
      "Epoch 32\n",
      "Training set accuracy: 85.90833333333333\n",
      "Validation set accuracy: 88.3\n",
      "Training set loss: 8893215.19349372\n",
      "Validation set loss: 59646.669120946346\n",
      "Epoch 33\n",
      "Training set accuracy: 86.18333333333334\n",
      "Validation set accuracy: 88.7\n",
      "Training set loss: 8804269.143441744\n",
      "Validation set loss: 59026.99206163892\n",
      "Epoch 34\n",
      "Training set accuracy: 86.58333333333333\n",
      "Validation set accuracy: 88.8\n",
      "Training set loss: 8718102.857613947\n",
      "Validation set loss: 58426.36343041237\n",
      "Epoch 35\n",
      "Training set accuracy: 86.93333333333332\n",
      "Validation set accuracy: 88.9\n",
      "Training set loss: 8634559.383955672\n",
      "Validation set loss: 57843.7596637105\n",
      "Epoch 36\n",
      "Training set accuracy: 87.175\n",
      "Validation set accuracy: 88.9\n",
      "Training set loss: 8553495.87966752\n",
      "Validation set loss: 57278.24435613926\n",
      "Epoch 37\n",
      "Training set accuracy: 87.43333333333332\n",
      "Validation set accuracy: 89.2\n",
      "Training set loss: 8474781.927732704\n",
      "Validation set loss: 56728.95823070405\n",
      "Epoch 38\n",
      "Training set accuracy: 87.63333333333333\n",
      "Validation set accuracy: 89.4\n",
      "Training set loss: 8398298.088063693\n",
      "Validation set loss: 56195.11047540727\n",
      "Epoch 39\n",
      "Training set accuracy: 87.93333333333334\n",
      "Validation set accuracy: 89.7\n",
      "Training set loss: 8323934.6470433315\n",
      "Validation set loss: 55675.9712391761\n",
      "Epoch 40\n",
      "Training set accuracy: 88.14999999999999\n",
      "Validation set accuracy: 89.8\n",
      "Training set loss: 8251590.535330903\n",
      "Validation set loss: 55170.865114243665\n",
      "Epoch 41\n",
      "Training set accuracy: 88.38333333333334\n",
      "Validation set accuracy: 90.2\n",
      "Training set loss: 8181172.388784637\n",
      "Validation set loss: 54679.16546017444\n",
      "Epoch 42\n",
      "Training set accuracy: 88.625\n",
      "Validation set accuracy: 90.3\n",
      "Training set loss: 8112593.731448747\n",
      "Validation set loss: 54200.28944786531\n",
      "Epoch 43\n",
      "Training set accuracy: 88.79166666666667\n",
      "Validation set accuracy: 90.4\n",
      "Training set loss: 8045774.262921639\n",
      "Validation set loss: 53733.69372099872\n",
      "Epoch 44\n",
      "Training set accuracy: 89.1\n",
      "Validation set accuracy: 90.60000000000001\n",
      "Training set loss: 7980639.235212139\n",
      "Validation set loss: 53278.87058831993\n",
      "Epoch 45\n",
      "Training set accuracy: 89.35833333333333\n",
      "Validation set accuracy: 90.8\n",
      "Training set loss: 7917118.906499357\n",
      "Validation set loss: 52835.344673341904\n",
      "Epoch 46\n",
      "Training set accuracy: 89.55\n",
      "Validation set accuracy: 90.8\n",
      "Training set loss: 7855148.06113935\n",
      "Validation set loss: 52402.66995913239\n",
      "Epoch 47\n",
      "Training set accuracy: 89.725\n",
      "Validation set accuracy: 91.2\n",
      "Training set loss: 7794665.586865652\n",
      "Validation set loss: 51980.42717510041\n",
      "Epoch 48\n",
      "Training set accuracy: 89.91666666666667\n",
      "Validation set accuracy: 91.60000000000001\n",
      "Training set loss: 7735614.101476696\n",
      "Validation set loss: 51568.22148047535\n",
      "Epoch 49\n",
      "Training set accuracy: 90.14999999999999\n",
      "Validation set accuracy: 91.8\n",
      "Training set loss: 7677939.622433769\n",
      "Validation set loss: 51165.68040572195\n",
      "Epoch 50\n",
      "Training set accuracy: 90.31666666666666\n",
      "Validation set accuracy: 91.8\n",
      "Training set loss: 7621591.273742406\n",
      "Validation set loss: 50772.45201867046\n",
      "Epoch 51\n",
      "Training set accuracy: 90.49166666666667\n",
      "Validation set accuracy: 91.9\n",
      "Training set loss: 7566521.02529574\n",
      "Validation set loss: 50388.203286824275\n",
      "Epoch 52\n",
      "Training set accuracy: 90.675\n",
      "Validation set accuracy: 92.0\n",
      "Training set loss: 7512683.46053633\n",
      "Validation set loss: 50012.618611279504\n",
      "Epoch 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 90.85\n",
      "Validation set accuracy: 92.0\n",
      "Training set loss: 7460035.568871786\n",
      "Validation set loss: 49645.39851107987\n",
      "Epoch 54\n",
      "Training set accuracy: 91.00833333333334\n",
      "Validation set accuracy: 92.0\n",
      "Training set loss: 7408536.559769466\n",
      "Validation set loss: 49286.25843969878\n",
      "Epoch 55\n",
      "Training set accuracy: 91.14999999999999\n",
      "Validation set accuracy: 92.10000000000001\n",
      "Training set loss: 7358147.6958742635\n",
      "Validation set loss: 48934.92771781643\n",
      "Epoch 56\n",
      "Training set accuracy: 91.28333333333333\n",
      "Validation set accuracy: 92.2\n",
      "Training set loss: 7308832.142850312\n",
      "Validation set loss: 48591.14856865239\n",
      "Epoch 57\n",
      "Training set accuracy: 91.38333333333334\n",
      "Validation set accuracy: 92.4\n",
      "Training set loss: 7260554.833954745\n",
      "Validation set loss: 48254.67524392901\n",
      "Epoch 58\n",
      "Training set accuracy: 91.50833333333334\n",
      "Validation set accuracy: 92.60000000000001\n",
      "Training set loss: 7213282.347612226\n",
      "Validation set loss: 47925.273230084335\n",
      "Epoch 59\n",
      "Training set accuracy: 91.55833333333334\n",
      "Validation set accuracy: 92.80000000000001\n",
      "Training set loss: 7166982.7964853905\n",
      "Validation set loss: 47602.71852569389\n",
      "Epoch 60\n",
      "Training set accuracy: 91.675\n",
      "Validation set accuracy: 92.9\n",
      "Training set loss: 7121625.726730433\n",
      "Validation set loss: 47286.79698220234\n",
      "Epoch 61\n",
      "Training set accuracy: 91.75833333333333\n",
      "Validation set accuracy: 93.0\n",
      "Training set loss: 7077182.0262925355\n",
      "Validation set loss: 46977.30370106485\n",
      "Epoch 62\n",
      "Training set accuracy: 91.85\n",
      "Validation set accuracy: 93.10000000000001\n",
      "Training set loss: 7033623.841242797\n",
      "Validation set loss: 46674.042481251745\n",
      "Epoch 63\n",
      "Training set accuracy: 91.95833333333333\n",
      "Validation set accuracy: 93.2\n",
      "Training set loss: 6990924.499279945\n",
      "Validation set loss: 46376.825311810644\n",
      "Epoch 64\n",
      "Training set accuracy: 92.11666666666667\n",
      "Validation set accuracy: 93.30000000000001\n",
      "Training set loss: 6949058.439630392\n",
      "Validation set loss: 46085.47190482959\n",
      "Epoch 65\n",
      "Training set accuracy: 92.25\n",
      "Validation set accuracy: 93.5\n",
      "Training set loss: 6908001.148673717\n",
      "Validation set loss: 45799.80926469473\n",
      "Epoch 66\n",
      "Training set accuracy: 92.375\n",
      "Validation set accuracy: 93.7\n",
      "Training set loss: 6867729.100699179\n",
      "Validation set loss: 45519.671290028724\n",
      "Epoch 67\n",
      "Training set accuracy: 92.40833333333333\n",
      "Validation set accuracy: 93.8\n",
      "Training set loss: 6828219.703273922\n",
      "Validation set loss: 45244.89840511704\n",
      "Epoch 68\n",
      "Training set accuracy: 92.50833333333334\n",
      "Validation set accuracy: 93.8\n",
      "Training set loss: 6789451.246760828\n",
      "Validation set loss: 44975.337217992084\n",
      "Epoch 69\n",
      "Training set accuracy: 92.59166666666667\n",
      "Validation set accuracy: 93.8\n",
      "Training set loss: 6751402.857580502\n",
      "Validation set loss: 44710.8402026763\n",
      "Epoch 70\n",
      "Training set accuracy: 92.65\n",
      "Validation set accuracy: 93.89999999999999\n",
      "Training set loss: 6714054.454857199\n",
      "Validation set loss: 44451.265403357545\n",
      "Epoch 71\n",
      "Training set accuracy: 92.70833333333334\n",
      "Validation set accuracy: 93.89999999999999\n",
      "Training set loss: 6677386.710129527\n",
      "Validation set loss: 44196.476158521546\n",
      "Epoch 72\n",
      "Training set accuracy: 92.77499999999999\n",
      "Validation set accuracy: 94.1\n",
      "Training set loss: 6641381.009843018\n",
      "Validation set loss: 43946.34084327889\n",
      "Epoch 73\n",
      "Training set accuracy: 92.84166666666667\n",
      "Validation set accuracy: 94.1\n",
      "Training set loss: 6606019.420372982\n",
      "Validation set loss: 43700.73262831513\n",
      "Epoch 74\n",
      "Training set accuracy: 92.89166666666667\n",
      "Validation set accuracy: 94.19999999999999\n",
      "Training set loss: 6571284.655352046\n",
      "Validation set loss: 43459.52925405715\n",
      "Epoch 75\n",
      "Training set accuracy: 92.95\n",
      "Validation set accuracy: 94.19999999999999\n",
      "Training set loss: 6537160.04510387\n",
      "Validation set loss: 43222.6128187967\n",
      "Epoch 76\n",
      "Training set accuracy: 93.025\n",
      "Validation set accuracy: 94.19999999999999\n",
      "Training set loss: 6503629.508002432\n",
      "Validation set loss: 42989.86957964047\n",
      "Epoch 77\n",
      "Training set accuracy: 93.075\n",
      "Validation set accuracy: 94.19999999999999\n",
      "Training set loss: 6470677.523597629\n",
      "Validation set loss: 42761.189765268835\n",
      "Epoch 78\n",
      "Training set accuracy: 93.09166666666667\n",
      "Validation set accuracy: 94.19999999999999\n",
      "Training set loss: 6438289.107362457\n",
      "Validation set loss: 42536.46739958819\n",
      "Epoch 79\n",
      "Training set accuracy: 93.15\n",
      "Validation set accuracy: 94.39999999999999\n",
      "Training set loss: 6406449.786933249\n",
      "Validation set loss: 42315.60013544957\n",
      "Epoch 80\n",
      "Training set accuracy: 93.2\n",
      "Validation set accuracy: 94.39999999999999\n",
      "Training set loss: 6375145.5797259165\n",
      "Validation set loss: 42098.489097684374\n",
      "Epoch 81\n",
      "Training set accuracy: 93.25833333333333\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 6344362.971823443\n",
      "Validation set loss: 41885.03873478073\n",
      "Epoch 82\n",
      "Training set accuracy: 93.34166666666667\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 6314088.898039605\n",
      "Validation set loss: 41675.15667858431\n",
      "Epoch 83\n",
      "Training set accuracy: 93.375\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 6284310.723072564\n",
      "Validation set loss: 41468.75361146278\n",
      "Epoch 84\n",
      "Training set accuracy: 93.425\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 6255016.2236712575\n",
      "Validation set loss: 41265.74314042513\n",
      "Epoch 85\n",
      "Training set accuracy: 93.46666666666667\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 6226193.571742473\n",
      "Validation set loss: 41066.041677729016\n",
      "Epoch 86\n",
      "Training set accuracy: 93.54166666666667\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 6197831.318334579\n",
      "Validation set loss: 40869.56832754947\n",
      "Epoch 87\n",
      "Training set accuracy: 93.58333333333333\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 6169918.378439467\n",
      "Validation set loss: 40676.24477832003\n",
      "Epoch 88\n",
      "Training set accuracy: 93.65\n",
      "Validation set accuracy: 94.5\n",
      "Training set loss: 6142444.016558132\n",
      "Validation set loss: 40485.995200384605\n",
      "Epoch 89\n",
      "Training set accuracy: 93.69166666666666\n",
      "Validation set accuracy: 94.6\n",
      "Training set loss: 6115397.832980515\n",
      "Validation set loss: 40298.74614863512\n",
      "Epoch 90\n",
      "Training set accuracy: 93.75\n",
      "Validation set accuracy: 94.6\n",
      "Training set loss: 6088769.750735404\n",
      "Validation set loss: 40114.42646982465\n",
      "Epoch 91\n",
      "Training set accuracy: 93.77499999999999\n",
      "Validation set accuracy: 94.69999999999999\n",
      "Training set loss: 6062550.003167385\n",
      "Validation set loss: 39932.96721428274\n",
      "Epoch 92\n",
      "Training set accuracy: 93.8\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 6036729.122103769\n",
      "Validation set loss: 39754.30155176804\n",
      "Epoch 93\n",
      "Training set accuracy: 93.80833333333334\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 6011297.926575895\n",
      "Validation set loss: 39578.364691221555\n",
      "Epoch 94\n",
      "Training set accuracy: 93.83333333333333\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 5986247.512061441\n",
      "Validation set loss: 39405.09380419776\n",
      "Epoch 95\n",
      "Training set accuracy: 93.86666666666666\n",
      "Validation set accuracy: 94.69999999999999\n",
      "Training set loss: 5961569.240219065\n",
      "Validation set loss: 39234.42795176541\n",
      "Epoch 96\n",
      "Training set accuracy: 93.875\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 5937254.729086098\n",
      "Validation set loss: 39066.30801468913\n",
      "Epoch 97\n",
      "Training set accuracy: 93.89166666666667\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 5913295.843714244\n",
      "Validation set loss: 38900.67662670935\n",
      "Epoch 98\n",
      "Training set accuracy: 93.91666666666667\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 5889684.68721868\n",
      "Validation set loss: 38737.47811075741\n",
      "Epoch 99\n",
      "Training set accuracy: 93.95833333333333\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 5866413.592218631\n",
      "Validation set loss: 38576.658417947896\n",
      "Epoch 100\n",
      "Training set accuracy: 93.95833333333333\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 5843475.112647812\n",
      "Validation set loss: 38418.16506920378\n",
      "Epoch 101\n",
      "Training set accuracy: 93.99166666666666\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 5820862.015916375\n",
      "Validation set loss: 38261.947099378165\n",
      "Epoch 102\n",
      "Training set accuracy: 94.04166666666667\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 5798567.275404754\n",
      "Validation set loss: 38107.95500374512\n",
      "Epoch 103\n",
      "Training set accuracy: 94.05\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 5776584.063273608\n",
      "Validation set loss: 37956.140686740364\n",
      "Epoch 104\n",
      "Training set accuracy: 94.075\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 5754905.743573206\n",
      "Validation set loss: 37806.45741283868\n",
      "Epoch 105\n",
      "Training set accuracy: 94.08333333333333\n",
      "Validation set accuracy: 94.8\n",
      "Training set loss: 5733525.865637489\n",
      "Validation set loss: 37658.859759464154\n",
      "Epoch 106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 94.075\n",
      "Validation set accuracy: 94.89999999999999\n",
      "Training set loss: 5712438.157748826\n",
      "Validation set loss: 37513.303571831864\n",
      "Epoch 107\n",
      "Training set accuracy: 94.09166666666667\n",
      "Validation set accuracy: 95.0\n",
      "Training set loss: 5691636.521059905\n",
      "Validation set loss: 37369.745919630026\n",
      "Epoch 108\n",
      "Training set accuracy: 94.1\n",
      "Validation set accuracy: 95.0\n",
      "Training set loss: 5671115.023761182\n",
      "Validation set loss: 37228.14505545276\n",
      "Epoch 109\n",
      "Training set accuracy: 94.10833333333333\n",
      "Validation set accuracy: 95.0\n",
      "Training set loss: 5650867.895481058\n",
      "Validation set loss: 37088.46037490156\n",
      "Epoch 110\n",
      "Training set accuracy: 94.125\n",
      "Validation set accuracy: 95.0\n",
      "Training set loss: 5630889.521908718\n",
      "Validation set loss: 36950.65237827651\n",
      "Epoch 111\n",
      "Training set accuracy: 94.15833333333333\n",
      "Validation set accuracy: 95.0\n",
      "Training set loss: 5611174.439628855\n",
      "Validation set loss: 36814.68263378332\n",
      "Epoch 112\n",
      "Training set accuracy: 94.20833333333334\n",
      "Validation set accuracy: 95.19999999999999\n",
      "Training set loss: 5591717.3311582\n",
      "Validation set loss: 36680.51374218688\n",
      "Epoch 113\n",
      "Training set accuracy: 94.22500000000001\n",
      "Validation set accuracy: 95.19999999999999\n",
      "Training set loss: 5572513.020175418\n",
      "Validation set loss: 36548.10930284444\n",
      "Epoch 114\n",
      "Training set accuracy: 94.23333333333333\n",
      "Validation set accuracy: 95.19999999999999\n",
      "Training set loss: 5553556.4669344155\n",
      "Validation set loss: 36417.43388105663\n",
      "Epoch 115\n",
      "Training set accuracy: 94.25833333333333\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 5534842.763854008\n",
      "Validation set loss: 36288.452976675246\n",
      "Epoch 116\n",
      "Training set accuracy: 94.26666666666667\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 5516367.131275247\n",
      "Validation set loss: 36161.132993915126\n",
      "Epoch 117\n",
      "Training set accuracy: 94.28333333333333\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 5498124.913379172\n",
      "Validation set loss: 36035.44121231224\n",
      "Epoch 118\n",
      "Training set accuracy: 94.29166666666666\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 5480111.574258146\n",
      "Validation set loss: 35911.34575878178\n",
      "Epoch 119\n",
      "Training set accuracy: 94.30833333333334\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 5462322.694133913\n",
      "Validation set loss: 35788.8155807256\n",
      "Epoch 120\n",
      "Training set accuracy: 94.35\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 5444753.965715964\n",
      "Validation set loss: 35667.82042014415\n",
      "Epoch 121\n",
      "Training set accuracy: 94.35\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 5427401.190694569\n",
      "Validation set loss: 35548.33078871026\n",
      "Epoch 122\n",
      "Training set accuracy: 94.34166666666667\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 5410260.276361909\n",
      "Validation set loss: 35430.31794376265\n",
      "Epoch 123\n",
      "Training set accuracy: 94.35833333333333\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 5393327.232356926\n",
      "Validation set loss: 35313.75386518123\n",
      "Epoch 124\n",
      "Training set accuracy: 94.39166666666667\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 5376598.167528075\n",
      "Validation set loss: 35198.61123310531\n",
      "Epoch 125\n",
      "Training set accuracy: 94.39999999999999\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 5360069.286908794\n",
      "Validation set loss: 35084.86340646156\n",
      "Epoch 126\n",
      "Training set accuracy: 94.39166666666667\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 5343736.888802006\n",
      "Validation set loss: 34972.48440226573\n",
      "Epoch 127\n",
      "Training set accuracy: 94.39999999999999\n",
      "Validation set accuracy: 95.3\n",
      "Training set loss: 5327597.3619680945\n",
      "Validation set loss: 34861.44887566769\n",
      "Epoch 128\n",
      "Training set accuracy: 94.40833333333333\n",
      "Validation set accuracy: 95.5\n",
      "Training set loss: 5311647.182912325\n",
      "Validation set loss: 34751.732100707944\n",
      "Epoch 129\n"
     ]
    }
   ],
   "source": [
    "epoch, accuracy_training, accuracy_validation, loss_training, loss_validation = logistic_regression(trainxs, trainys, devxs, devys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis([-1, epoch, min(loss_validation) - 1000000, max(loss_training)])\n",
    "plt.plot(loss_training, label='training set loss')\n",
    "plt.plot(loss_validation, label='validation set loss', color='r')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis([-1, epoch, min(accuracy_training), max(accuracy_training) + 5])\n",
    "plt.plot(accuracy_training, label='training set accuracy')\n",
    "plt.plot(accuracy_validation, label='validation set accuracy', color='r')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = accuracy_validation.index(max(accuracy_validation))\n",
    "print(\"Best epoch =\", ind)\n",
    "print(\"Accuracy on training set =\", accuracy_training[ind])\n",
    "print(\"Accuracy on validation set =\", accuracy_validation[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(w, b):\n",
    "    toflatten = (w, [b])\n",
    "    vec = np.zeros(sum(len(x) for x in toflatten))\n",
    "    offset = 0\n",
    "    for parameter in toflatten:\n",
    "        vec[offset:offset + len(parameter)] = parameter\n",
    "        offset += len(parameter)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unflatten(w, b, vec):\n",
    "    tounflatten = (w, [b])\n",
    "    offset = 0\n",
    "    for parameter in tounflatten:\n",
    "        parameter[:] = vec[offset:offset + len(parameter)]\n",
    "        offset += len(parameter)\n",
    "    return tounflatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdfprime(w, b, x, y):\n",
    "    epsilon  = 0.000001\n",
    "    grad_w = np.zeros_like(w)\n",
    "    grad_b = 0.0\n",
    "    vecm     = flatten(w, b)\n",
    "    vecgradm = flatten(grad_w, grad_b)\n",
    "    \n",
    "    for i in range(len(vecm)):\n",
    "        wi           = vecm[i]\n",
    "\n",
    "        vecm[i]     += epsilon/2       \n",
    "        w_j, b_j     = unflatten(grad_w, grad_b, vecm)\n",
    "        r            = loss(y, f(x, w_j, b_j))\n",
    "        vecm[i]      = wi\n",
    "        vecm[i]     -= epsilon/2\n",
    "        w_j, b_j     = unflatten(grad_w, grad_b, vecm)\n",
    "        l            = loss(y, f(x, w_j, b_j))\n",
    "        vecgradm[i]  = (r - l)/epsilon\n",
    "\n",
    "        vecm[i]      = wi\n",
    "\n",
    "    return unflatten(grad_w, grad_b, vecgradm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fprime(n, x, y, w, b):\n",
    "    grad_w = np.zeros(n)\n",
    "    grad_b = 0.0\n",
    "    \n",
    "    #Forward pass\n",
    "    z = np.dot(w, x) + b\n",
    "    y_hat = logistic_func(z)\n",
    "    \n",
    "    #Backward pass\n",
    "    grad_z = (y_hat - y) * logistic_der(z)\n",
    "    grad_w += x * (y_hat - y) * (1 - y_hat) * y_hat \n",
    "    grad_b += (y_hat - y) * (1 - y_hat) * y_hat\n",
    "    \n",
    "    return (grad_w, [grad_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trainxs[0]\n",
    "y = trainys[0]\n",
    "w = np.random.random(784) / 100\n",
    "grad_w, grad_b = fprime(trainxs.shape[1], x, y, w, 0.0)\n",
    "fd_grad_w, fd_grad_b = fdfprime(w, 0.0, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_b = np.subtract(fd_grad_b,grad_b)\n",
    "fd_w = np.subtract(fd_grad_w,grad_w)\n",
    "max_fd = fd_w.max()\n",
    "print(fd_b)\n",
    "print(fd_w)\n",
    "print(\"Max difference for w:\", max_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
